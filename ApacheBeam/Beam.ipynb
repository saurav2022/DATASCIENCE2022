{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Beam\n",
    "* Unified + Portability \n",
    "\n",
    "* Open source, portable and unified data processing framework used for both batch  and streaming data ETL and analytics.\n",
    "\n",
    "* It can work on all execution engines (Spark, Dataflow, Hadoop Mapreduce, Flink, ...)\n",
    "\n",
    "* It is execution platform, data and programming language agnostic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History\n",
    "* ~2004: Apache Hadoop (Java)\n",
    "* ~2009 : Apache Spark (Initially Java, Python later)\n",
    "* Apache Flink, Apache Storm \n",
    "* FlumeJava (Google)\n",
    "* ~2013 : MillWheel (Google)\n",
    "* Apache Samza, Apache Apex, Apache Heron, Cloud Dataflow(GCP)\n",
    "* ~2016 : Gearpump, Apache Nemo\n",
    "* ~2018-19 : Apache Beam "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Supported languages: Python, Java, Go, etc.\n",
    "* Based on the conept of pipeline. (Input Data --> Read --> Transform --> Dump Output data )\n",
    "* Pcollection : The Dataset\n",
    "* Ptransform : Transformation logic on data.\n",
    "- Types:\n",
    "    1. Parallel Processing (ParDo)\n",
    "    2. GroupBy\n",
    "    3. Combine\n",
    "    4. Flatten\n",
    "    5. Partitioning\n",
    "* Pcollection1 --(Ptransform1)--> Pcollection2 ---(Ptransform2)---> Pcollection3\n",
    "* Pcol1 -(Ptr1)-> Pcol2\n",
    "* Pcol1 -(Ptr2)->Pcol3\n",
    "* Side input : Addl data to support transformation.\n",
    "* Runner : Framework on which we want to run the logic (Spark, Dataflow, Flink.)\n",
    "* Windowing\n",
    "* Trigger\n",
    "* Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install apache_beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: apache-beam[interactive]\n"
     ]
    }
   ],
   "source": [
    "!pip install apache-beam[interactive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = beam.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        if (typeof window.interactive_beam_jquery == 'undefined') {\n          var jqueryScript = document.createElement('script');\n          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n          jqueryScript.type = 'text/javascript';\n          jqueryScript.onload = function() {\n            var datatableScript = document.createElement('script');\n            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n            datatableScript.type = 'text/javascript';\n            datatableScript.onload = function() {\n              window.interactive_beam_jquery = jQuery.noConflict(true);\n              window.interactive_beam_jquery(document).ready(function($){\n                \n              });\n            }\n            document.head.appendChild(datatableScript);\n          };\n          document.head.appendChild(jqueryScript);\n        } else {\n          window.interactive_beam_jquery(document).ready(function($){\n            \n          });\n        }"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ip = (\n",
    "    pipe\n",
    "    |beam.io.ReadFromText('./online_retail_mini.csv', skip_header_lines=True)\n",
    "    |beam.Map(lambda x: x.split(\",\"))\n",
    "    |beam.Filter(lambda x: x[1]=='21480')\n",
    "    |beam.combiners.Count.Globally()\n",
    "    |beam.Map(print)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x147900250>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Combine the aforementioned 3 code blocks into one.\n",
    "with beam.Pipeline() as pipe1:\n",
    "    ip1 = (\n",
    "        pipe1\n",
    "        |beam.io.ReadFromText('./online_retail_mini.csv', skip_header_lines=True)\n",
    "        |beam.Map(lambda x: x.split(\",\"))\n",
    "        |beam.Filter(lambda x: x[1]=='21410')\n",
    "        |beam.combiners.Count.Globally()\n",
    "        |beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(element):\n",
    "    if element[1] == '21480':\n",
    "        return element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as pipe1:\n",
    "    ip1 = (\n",
    "        pipe1\n",
    "        |beam.io.ReadFromText('./online_retail_mini.csv', skip_header_lines=True)\n",
    "        |beam.Map(lambda x: x.split(\",\"))\n",
    "        |beam.Filter(filter_data)\n",
    "        |beam.combiners.Count.Globally()\n",
    "        |beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregations Per Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('15CM CHRISTMAS GLASS BALL 20 LIGHTS', 3)\n",
      "('PINK CHERRY LIGHTS', 3)\n",
      "(' WHITE CHERRY LIGHTS', 4)\n",
      "('\"RECORD FRAME 7\"\" SINGLE SIZE \"', 2)\n",
      "('STRAWBERRY CERAMIC TRINKET BOX', 4)\n",
      "('PINK DOUGHNUT TRINKET POT ', 3)\n",
      "('SAVE THE PLANET MUG', 3)\n",
      "('FANCY FONT HOME SWEET HOME DOORMAT', 3)\n",
      "('CAT BOWL ', 2)\n",
      "('\"DOG BOWL ', 2)\n",
      "('HEART MEASURING SPOONS LARGE', 1)\n",
      "('LUNCHBOX WITH CUTLERY FAIRY CAKES ', 3)\n",
      "('DOOR MAT BLACK FLOCK ', 1)\n",
      "('LOVE BUILDING BLOCK WORD', 3)\n",
      "('HOME BUILDING BLOCK WORD', 4)\n",
      "('ASSORTED COLOUR BIRD ORNAMENT', 5)\n",
      "(' PEACE WOODEN BLOCK LETTERS', 1)\n",
      "('CHRISTMAS CRAFT WHITE FAIRY ', 4)\n",
      "('HEART IVORY TRELLIS LARGE', 2)\n",
      "('HEART FILIGREE DOVE LARGE', 2)\n",
      "('FULL ENGLISH BREAKFAST PLATE', 2)\n",
      "('PIZZA PLATE IN BOX', 3)\n",
      "('BLACK DINER WALL CLOCK', 1)\n",
      "('SET OF 3 BLACK FLYING DUCKS', 1)\n",
      "('AREA PATROLLED METAL SIGN', 3)\n",
      "('PLEASE ONE PERSON  METAL SIGN', 5)\n",
      "('BATH BUILDING BLOCK WORD', 2)\n",
      "('CLASSIC WHITE FRAME', 1)\n",
      "('SMALL MARSHMALLOWS PINK BOWL', 1)\n",
      "('BISCUITS SMALL BOWL LIGHT BLUE', 1)\n",
      "('SCOTTIE DOG HOT WATER BOTTLE', 8)\n",
      "('CHRISTMAS CRAFT HEART DECORATIONS', 2)\n",
      "('CHRISTMAS CRAFT HEART STOCKING ', 1)\n",
      "('PARTY CONE CHRISTMAS DECORATION ', 6)\n",
      "('PEACE SMALL WOOD LETTERS', 2)\n",
      "('JOY LARGE WOOD LETTERS', 1)\n",
      "('CINAMMON & ORANGE WREATH', 2)\n",
      "('EUCALYPTUS & PINECONE  WREATH', 1)\n",
      "('WOODEN BOX ADVENT CALENDAR ', 3)\n",
      "('FLORAL BLUE MONSTER', 1)\n",
      "('RETRO COFFEE MUGS ASSORTED', 2)\n",
      "('INFLATABLE POLITICAL GLOBE ', 1)\n",
      "('STRIPES DESIGN MONKEY DOLL', 1)\n",
      "('BLUE PADDED SOFT MOBILE', 1)\n",
      "('PACK OF 6 SKULL PAPER CUPS', 1)\n",
      "('PACK OF 20 SKULL PAPER NAPKINS', 1)\n",
      "('HANGING HEART ZINC T-LIGHT HOLDER', 4)\n",
      "('PINK BLUE FELT CRAFT TRINKET BOX', 4)\n",
      "('FELTCRAFT DOLL ROSIE', 2)\n",
      "('FELTCRAFT DOLL MARIA', 3)\n",
      "('FELTCRAFT DOLL EMILY', 3)\n",
      "('VINTAGE SNAKES & LADDERS', 6)\n",
      "('CHOCOLATE HOT WATER BOTTLE', 3)\n",
      "('DINOSAURS  WRITING SET ', 1)\n",
      "('SET OF MEADOW  FLOWER STICKERS', 2)\n",
      "('CHARLIE AND LOLA CHARLOTTE BAG', 2)\n",
      "('JUMBO BAG CHARLIE AND LOLA TOYS', 1)\n",
      "('JUMBO BAG TOYS ', 2)\n",
      "('COUNTRY COTTAGE  DOORSTOP GREEN', 2)\n",
      "('GINGHAM HEART  DOORSTOP RED', 2)\n",
      "('CHARLIE+LOLA RED HOT WATER BOTTLE ', 1)\n",
      "('CHARLIE LOLA BLUE HOT WATER BOTTLE ', 2)\n",
      "('CHARLIE+LOLA PINK HOT WATER BOTTLE', 4)\n",
      "('CHARLIE + LOLA RED HOT WATER BOTTLE', 3)\n",
      "('TOMATO CHARLIE+LOLA COASTER SET', 1)\n",
      "('CARROT CHARLIE+LOLA COASTER SET', 1)\n",
      "('CHARLIE + LOLA BISCUITS TINS', 1)\n",
      "('CHARLIE AND LOLA FIGURES TINS', 1)\n",
      "('CHARLIE & LOLA WASTEPAPER BIN BLUE', 1)\n",
      "('CHARLIE & LOLA WASTEPAPER BIN FLORA', 1)\n",
      "('CHRISTMAS PUDDING TRINKET POT ', 2)\n",
      "('BAKING SET 9 PIECE RETROSPOT ', 6)\n",
      "('RETRO SPOT TEA SET CERAMIC 11 PC ', 7)\n",
      "('LUNCHBOX WITH CUTLERY RETROSPOT ', 1)\n",
      "('BLACK/BLUE DOTS RUFFLED UMBRELLA', 2)\n",
      "('RED/WHITE DOTS RUFFLED UMBRELLA', 2)\n",
      "('WRAP ENGLISH ROSE ', 1)\n",
      "('WRAP BLUE RUSSIAN FOLKART', 1)\n",
      "('SET OF THREE VINTAGE GIFT WRAPS', 6)\n",
      "('RETRO SPORT PARTY BAG + STICKER SET', 2)\n",
      "('ASSORTED CAKES FRIDGE MAGNETS', 1)\n",
      "(' VINTAGE DESIGN GIFT TAGS', 3)\n",
      "('RED TOADSTOOL LED NIGHT LIGHT', 3)\n",
      "('SET/3 RUSSIAN DOLL STACKING TINS', 2)\n",
      "('PACK 20 DOLLY PEGS', 1)\n",
      "('ASSORTED COLOUR MINI CASES', 1)\n",
      "('POSTAGE', 5)\n",
      "('BIRD DECORATION RED SPOT', 3)\n",
      "('RED WOOLLY HOTTIE WHITE HEART.', 2)\n",
      "('UNION JACK GUNS & ROSES  DOORMAT', 2)\n",
      "('YELLOW + BROWN BEAR FELT PURSE KIT', 2)\n",
      "('WHITE HANGING HEART T-LIGHT HOLDER', 7)\n",
      "('KINGS CHOICE SMALL TUBE MATCHES', 3)\n",
      "('KINGS CHOICE GIANT TUBE MATCHES', 2)\n",
      "('KINGS CHOICE CIGAR BOX MATCHES ', 3)\n",
      "('EMPIRE TISSUE BOX', 1)\n",
      "('\"GREETING CARD', 2)\n",
      "('RAINY LADIES BIRTHDAY CARD', 2)\n",
      "('BANQUET BIRTHDAY  CARD  ', 1)\n",
      "('SPACE BOY BIRTHDAY CARD', 2)\n",
      "('RING OF ROSES BIRTHDAY CARD', 1)\n",
      "('BOTANICAL LAVENDER BIRTHDAY CARD', 1)\n",
      "('SET3 BOOK BOX GREEN GINGHAM FLOWER ', 1)\n",
      "('SET/3 RED GINGHAM ROSE STORAGE BOX', 2)\n",
      "('SET 12 RETRO WHITE CHALK STICKS', 2)\n",
      "('VINTAGE SNAP CARDS', 4)\n",
      "('BINGO SET', 3)\n",
      "('VICTORIAN SEWING KIT', 1)\n",
      "('RETRO RED SPOTTY WASHING UP GLOVES', 5)\n",
      "('SET/2 RED SPOTTY TEA TOWELS ', 1)\n",
      "('VINYL RECORD FRAME SILVER', 1)\n",
      "('BATHROOM METAL SIGN', 1)\n",
      "('LADIES & GENTLEMEN METAL SIGN', 3)\n",
      "('RED SPOTTY OVEN GLOVE DOUBLE', 3)\n",
      "('PINK FELT HANGING HEART W FLOWER', 1)\n",
      "('BLUE FELT HANGING HEART W FLOWER', 1)\n",
      "('RETRO SPOT LAMP', 3)\n",
      "('PARTY CONES CANDY ASSORTED', 1)\n",
      "('HEART STRING MEMO HOLDER HANGING', 1)\n",
      "('FOLKART BAUBLE CHRISTMAS DECORATION', 1)\n",
      "('6 CROCHET STRAWBERRIES', 1)\n",
      "('SET OF 72 PINK HEART PAPER DOILIES', 1)\n",
      "('LOVEBIRD HANGING DECORATION WHITE ', 1)\n",
      "('WHITE TALL PORCELAIN T-LIGHT HOLDER', 1)\n",
      "('EDWARDIAN TOILET ROLL UNIT ', 1)\n",
      "('SET/6 STRAWBERRY PAPER CUPS', 1)\n",
      "('SET/6 WOODLAND PAPER CUPS', 1)\n",
      "('JUMBO BAG PINK VINTAGE PAISLEY', 3)\n",
      "('\"GARLAND ', 1)\n",
      "('SET/6 WOODLAND PAPER PLATES', 1)\n",
      "('RED HANGING HEART T-LIGHT HOLDER', 4)\n",
      "('VICTORIAN GLASS HANGING T-LIGHT', 1)\n",
      "('UNION JACK HOT WATER BOTTLE ', 8)\n",
      "('RED SPOT CERAMIC DRAWER KNOB', 3)\n",
      "(\"PAPER CHAIN KIT 50'S CHRISTMAS \", 13)\n",
      "('HEART FILIGREE DOVE  SMALL', 2)\n",
      "('FRYING PAN RED POLKADOT ', 1)\n",
      "('PAPER CHAIN KIT RETRO SPOT', 7)\n",
      "('HOT WATER BOTTLE TEA AND SYMPATHY', 4)\n",
      "('RED SPOT HEART HOT WATER BOTTLE', 3)\n",
      "('JUMBO BAG SCANDINAVIAN PAISLEY', 1)\n",
      "('JUMBO BAG RED WHITE SPOTTY ', 3)\n",
      "('\"CHARLOTTE BAG ', 3)\n",
      "('RED SPOTTY CHARLOTTE BAG', 1)\n",
      "('RETRO SPOT  CIGAR BOX MATCHES ', 1)\n",
      "('LUNCH BAG RED SPOTTY', 1)\n",
      "('LUNCH BAG CARS BLUE', 2)\n",
      "('LUNCH BAG WOODLAND', 1)\n",
      "('RED SPOTTY ROUND CAKE TINS', 2)\n",
      "('LARGE HEART MEASURING SPOONS', 1)\n",
      "('CREAM SWEETHEART MINI CHEST', 1)\n",
      "('GOLD APERITIF GLASS', 1)\n",
      "('GOLD WINE GLASS', 1)\n",
      "('GOLD WINE GOBLET', 1)\n",
      "('SILVER APERITIF GLASS', 1)\n",
      "('PAPER BUNTING WHITE LACE', 2)\n",
      "('CREAM FELT EASTER EGG BASKET', 2)\n",
      "(\"POTTING SHED SOW 'N' GROW SET\", 2)\n",
      "('POTTING SHED TWINE', 2)\n",
      "('ANTIQUE SILVER TEA GLASS ETCHED', 8)\n",
      "('PAPER BUNTING RETRO SPOTS', 2)\n",
      "('PURPLE SWEETHEART BRACELET', 2)\n",
      "('PINK SWEETHEART BRACELET', 2)\n",
      "('BLACK SWEETHEART BRACELET', 2)\n",
      "('GREEN SWEETHEART BRACELET', 2)\n",
      "('BLUE SWEETHEART BRACELET', 2)\n",
      "('BLACK DIAMANTE EXPANDABLE RING', 2)\n",
      "('AMETHYST DIAMANTE EXPANDABLE RING', 2)\n",
      "('MIDNIGHT BLUE PAIR HEART HAIR SLIDE', 2)\n",
      "('CRYSTAL PAIR HEART HAIR SLIDES', 2)\n",
      "('ROSE COLOUR PAIR HEART HAIR SLIDES', 2)\n",
      "('PINK ENAMEL+GLASS HAIR COMB', 2)\n",
      "('PURPLE ENAMEL+GLASS HAIR COMB', 2)\n",
      "('DIAMANTE BOW BROOCH BLACK COLOUR', 2)\n",
      "('PACK OF 60 PINK PAISLEY CAKE CASES', 1)\n",
      "('60 TEATIME FAIRY CAKE CASES', 2)\n",
      "('FELTCRAFT DOLL MOLLY', 3)\n",
      "('SET 10 LIGHTS NIGHT OWL', 1)\n",
      "('BIRDS MOBILE VINTAGE DESIGN', 1)\n",
      "('3 PIECE JIGSAW TOADSTOOLS', 1)\n",
      "('BOYS ALPHABET IRON ON PATCHES', 1)\n",
      "(' SILVER CHERRY LIGHTS', 2)\n",
      "('GIRLS ALPHABET IRON ON PATCHES ', 1)\n",
      "('RED STRIPE CERAMIC DRAWER KNOB', 1)\n",
      "('BLUE STRIPE CERAMIC DRAWER KNOB', 2)\n",
      "('BLUE SPOT CERAMIC DRAWER KNOB', 1)\n",
      "('WHITE SPOT RED CERAMIC DRAWER KNOB', 1)\n",
      "('WHITE SPOT BLUE CERAMIC DRAWER KNOB', 2)\n",
      "('BLUE CHARLIE+LOLA PERSONAL DOORSIGN', 2)\n",
      "('RED CHARLIE+LOLA PERSONAL DOORSIGN', 2)\n",
      "('KEEP OUT BOYS DOOR HANGER ', 2)\n",
      "('TOXIC AREA  DOOR HANGER ', 2)\n",
      "('DOOR HANGER  MUM + DADS ROOM', 1)\n",
      "('MOODY BOY  DOOR HANGER ', 1)\n",
      "('WOODEN FRAME ANTIQUE WHITE ', 1)\n",
      "('WOOD S/3 CABINET ANT WHITE FINISH', 2)\n",
      "('WOOD 2 DRAWER CABINET WHITE FINISH', 3)\n",
      "('PACK OF 72 RETRO SPOT CAKE CASES', 2)\n",
      "('FAIRY CAKE CANDLES', 1)\n",
      "('CERAMIC BOWL WITH STRAWBERRY DESIGN', 1)\n",
      "('CERAMIC CAKE BOWL + HANGING CAKES', 1)\n",
      "('85123a mixed', 1)\n",
      "('\"FOLDING UMBRELLA ', 2)\n",
      "('FOLDING UMBRELLA  PINK/WHITE  SPOT', 1)\n",
      "('FOLDING UMBRELLA  CREAM/MULTI  SPOT', 1)\n",
      "('FOLDING UMBRELLA  WHITE/RED  SPOT', 1)\n",
      "('PICCADILLY TEA SET', 1)\n",
      "('RETRO BLUE SPOTTY WASHING UP GLOVES', 2)\n",
      "('RETRO PINK SPOT WASHING UP GLOVES', 1)\n",
      "('FUNKY WASHING UP GLOVES ASSORTED', 1)\n",
      "('DOOR MAT FAIRY CAKE', 2)\n",
      "('FAWN BLUE HOT WATER BOTTLE', 2)\n",
      "('ANTIQUE LILY FAIRY LIGHTS', 3)\n",
      "('VINTAGE CREAM 3 BASKET CAKE STAND', 2)\n",
      "('short', 1)\n",
      "('21733 mixed', 1)\n",
      "('FELTCRAFT 6 FLOWER FRIENDS', 1)\n",
      "('MUSHROOM BLUE HOT WATER BOTTLE', 2)\n",
      "('CHICK GREY HOT WATER BOTTLE', 2)\n",
      "('GREY FLORAL FELTCRAFT SHOULDER BAG', 2)\n",
      "('PINK FLORAL FELTCRAFT SHOULDER BAG', 2)\n",
      "('PINK CROCHET CAT WITH SCARF', 1)\n",
      "('PINK CREAM FELT CRAFT TRINKET BOX ', 3)\n",
      "('PINK JUMPER LARRY THE LAMB', 1)\n",
      "(\"SET OF THREE 50'S GIFT WRAPS \", 2)\n",
      "('PARTY INVITES JAZZ HEARTS', 1)\n",
      "('PARTY INVITES WOODLAND', 1)\n",
      "('PINK 3 PIECE MINI DOTS CUTLERY SET', 2)\n",
      "('BLUE 3 PIECE MINI DOTS CUTLERY SET', 2)\n",
      "('COFFEE MUG CAT + BIRD DESIGN', 2)\n",
      "('COFFEE MUG DOG + BALL DESIGN', 4)\n",
      "('SWEETHEART CERAMIC TRINKET BOX', 4)\n",
      "('OPULENT VELVET CANDLE IN BOX', 1)\n",
      "('VINTAGE ROSE BEAD BRACELET BLUE', 1)\n",
      "('WHITE GLASS CHUNKY CHARM BRACELET', 1)\n",
      "('BLACK GEMSTONE BRACELET', 1)\n",
      "('CARNIVAL BRACELET', 2)\n",
      "('JUMBO STORAGE BAG SKULLS', 1)\n",
      "('DAIRY MAID CERAMIC BUTTER DISH', 2)\n",
      "('RETRO SPOT LARGE MILK JUG', 3)\n",
      "('KISS REINDEER SCANDINAVIAN STOCKING', 1)\n",
      "('LADYBIRD + BEE RAFFIA FOOD COVER', 1)\n",
      "('TEA TIME PARTY BUNTING', 1)\n",
      "('WEEKEND BAG VINTAGE ROSE PAISLEY', 1)\n",
      "('WHITE SKULL HOT WATER BOTTLE ', 3)\n",
      "('VINTAGE HEADS AND TAILS CARD GAME ', 8)\n",
      "('COLOUR GLASS. STAR T-LIGHT HOLDER', 2)\n",
      "('CERAMIC CAKE STAND + HANGING CAKES', 1)\n",
      "('MINI CAKE STAND WITH HANGING CAKES', 1)\n",
      "('VICTORIAN SEWING BOX LARGE', 2)\n",
      "('SET/3 TALL GLASS CANDLE HOLDER PINK', 3)\n",
      "(\"PINK FAIRY CAKE CHILD'S APRON\", 1)\n",
      "('PINK UNION JACK  LUGGAGE TAG', 1)\n",
      "('LAUNDRY 15C METAL SIGN', 1)\n",
      "('\"AIRLINE LOUNGE', 1)\n",
      "('METAL SIGN CUPCAKE SINGLE HOOK', 1)\n",
      "('NO JUNK MAIL METAL SIGN', 1)\n",
      "('PINK UNION JACK  PASSPORT COVER ', 2)\n",
      "(\"BLACK SIL'T SQU CANDLE PLATE \", 1)\n",
      "('WOODLAND CHARLOTTE BAG', 1)\n",
      "('POTTING SHED COFFEE MUG', 2)\n",
      "('POTTERING MUG', 1)\n",
      "('FAIRY SOAP SOAP HOLDER', 1)\n",
      "('UNION JACK FLAG PASSPORT COVER ', 3)\n",
      "('FLOWER VINE RAFFIA FOOD COVER', 1)\n",
      "('VINTAGE NOTEBOOK PARIS DAYS', 1)\n",
      "('SQUARE MIRROR CURTAIN', 1)\n",
      "('ENGLISH ROSE TEA SET IN GIFT BOX', 1)\n",
      "('GREEN 3 PIECE MINI DOTS CUTLERY SET', 2)\n",
      "('GREEN  SPOTTY PLATE ', 1)\n",
      "('GREEN SPOTTY CUP', 1)\n",
      "('BAG 500g SWIRLY MARBLES', 1)\n",
      "('VINTAGE SEASIDE JIGSAW PUZZLES', 2)\n",
      "('PINK STRAWBERRY HANDBAG ', 2)\n",
      "('GLITTER STAR GARLAND WITH BELLS ', 2)\n",
      "('HAIRCLIPS FORTIES FABRIC ASSORTED', 3)\n",
      "('RETRO SPOT SMALL TUBE MATCHES', 2)\n",
      "('JUMBO STORAGE BAG SUKI', 2)\n",
      "(\"CAROUSEL DES CHILD'S APRON\", 1)\n",
      "('RED 3 PIECE MINI DOTS CUTLERY SET', 2)\n",
      "('SET OF 2 FANCY FONT TEA TOWELS', 2)\n",
      "('CROSS STITCH ALPHABET CUSHION COVER', 1)\n",
      "('S/4 PISTACHIO LOVEBIRD COASTERS', 2)\n",
      "('HEART DECORATION PAINTED ZINC ', 1)\n",
      "('\"WHITE PEARL BEADED HEART', 1)\n",
      "('GINGHAM HEART DECORATION', 1)\n",
      "('BLUE  SPOTTY PLATE ', 1)\n",
      "('BLUE SPOTTY BOWL', 3)\n",
      "('FRAPPUCINO SCARF KNITTING KIT', 1)\n",
      "('WASH BAG VINTAGE ROSE PAISLEY', 1)\n",
      "('GREEN ROSE WASHBAG', 1)\n",
      "('BLUE/BROWN DOTS RUFFLED UMBRELLA', 2)\n",
      "('PINK/BROWN DOTS RUFFLED UMBRELLA', 1)\n",
      "('AGED GLASS SILVER T-LIGHT HOLDER', 1)\n",
      "('SILVER HANGING T-LIGHT HOLDER', 1)\n",
      "('CHOCOLATE THIS WAY METAL SIGN', 2)\n",
      "('MIRRORED WALL ART POPPIES', 1)\n",
      "('HAND OVER THE CHOCOLATE   SIGN ', 2)\n",
      "('PAINTED BIRD ASSORTED CHRISTMAS', 3)\n",
      "('12 PENCILS TALL TUBE POSY', 2)\n",
      "('12 PENCILS TALL TUBE SKULLS', 2)\n",
      "('LARGE HEART FLOWERS HOOK   ', 1)\n",
      "('2 DAISIES HAIR COMB', 1)\n",
      "('ANT WHITE WIRE HEART SPIRAL', 1)\n",
      "('GREEN VINTAGE EARRINGS ', 1)\n",
      "('FILIGREE DIAMANTE EARRINGS', 1)\n",
      "('PINK VINTAGE VICTORIAN EARRINGS', 1)\n",
      "('BROWN VINTAGE VICTORIAN EARRINGS', 1)\n",
      "('SILVER HOOP EARRINGS WITH FLOWER', 1)\n",
      "('RASPBERRY ANT COPPER FLOWER NECKLAC', 1)\n",
      "(\"NEW BAROQUE B'FLY NECKLACE RED\", 1)\n",
      "('\"FLOWER GLASS GARLAND NECKL.36\"\"BLACK\"', 1)\n",
      "('OLD ROSE COMBO BEAD NECKLACE', 1)\n",
      "('PINK/AMETHYST/GOLD NECKLACE', 1)\n",
      "('5 STRAND GLASS NECKLACE CRYSTAL', 1)\n",
      "('PURPLE CURRENT CANDLE RING', 1)\n",
      "('WHITE CHOCOLATE SCENT CANDLE', 1)\n",
      "('FOUR HOOK  WHITE LOVEBIRDS', 1)\n",
      "('DOOR MAT NEW ENGLAND', 1)\n",
      "('DOOR MAT GREEN PAISLEY ', 2)\n",
      "('GRAND CHOCOLATECANDLE', 1)\n",
      "('SET/3 DECOUPAGE STACKING TINS', 1)\n",
      "('GLITTER BUTTERFLY CLIPS', 2)\n",
      "('RIBBON REEL SPOTS DESIGN ', 1)\n",
      "('RIBBON REEL STRIPES DESIGN ', 1)\n",
      "('SHOE SHINE BOX ', 1)\n",
      "('PARTY METAL SIGN ', 1)\n",
      "('NO SINGING METAL SIGN', 2)\n",
      "('12 EGG HOUSE PAINTED WOOD', 1)\n",
      "('PINK HEART CANDY BUTTON CALCULATOR', 1)\n",
      "('PAPER BUNTING VINTAGE PAISLEY', 1)\n",
      "('SILVER MINI TAPE MEASURE ', 1)\n",
      "('ASSORTED SANTA CHRISTMAS DECORATION', 1)\n",
      "('NOEL WOODEN BLOCK LETTERS ', 1)\n",
      "('ZINC METAL HEART DECORATION', 3)\n",
      "('', 1)\n",
      "('YELLOW RED FLOWER PIGGY BANK', 1)\n",
      "('COLOURING PENCILS BROWN TUBE', 2)\n",
      "('GREY HEART HOT WATER BOTTLE', 3)\n",
      "('CAMOUFLAGE EAR MUFF HEADPHONES', 1)\n",
      "('LOCAL CAFE MUG', 1)\n",
      "('KNITTED UNION FLAG HOT WATER BOTTLE', 1)\n",
      "('BLUE WHITE SCARF HOT WATER BOTTLE', 3)\n",
      "('GEISHA GIRL CHOPSTICKS SET/5', 1)\n",
      "('URBAN CHIC CHOPSTICKS SET/5', 1)\n",
      "('POTTING SHED TEA MUG', 2)\n",
      "('KINGS CHOICE MUG', 1)\n",
      "('EIGHT PIECE DINOSAUR SET', 1)\n",
      "('EIGHT PIECE CREEPY CRAWLIE SET', 1)\n",
      "('EIGHT PIECE SNAKE  SET', 1)\n",
      "('RATTLE SNAKE EGGS', 1)\n",
      "('DINOSAUR KEYRINGS ASSORTED', 1)\n",
      "('ASSORTED TUTTI FRUTTI NOTEBOOK', 1)\n",
      "('CAKE STAND LACE WHITE', 1)\n",
      "('CAKE PLATE LOVEBIRD WHITE', 1)\n",
      "('COFFEE MUG PINK PAISLEY DESIGN', 1)\n",
      "('COFFEE MUG BLUE PAISLEY DESIGN', 1)\n",
      "('COFFEE MUG PEARS  DESIGN', 1)\n",
      "('COFFEE MUG APPLES DESIGN', 1)\n",
      "('PARTY CONES CARNIVAL ASSORTED', 1)\n",
      "('ANTIQUE GLASS HEART DECORATION ', 1)\n",
      "('ASSORTED TUTTI FRUTTI KEYRING', 1)\n",
      "('ANGEL DECORATION 3 BUTTONS ', 2)\n",
      "('STAR DECORATION RUSTIC', 1)\n",
      "('WOODEN BOX OF DOMINOES', 1)\n",
      "('GREEN CHRISTMAS TREE STRING 20LIGHT', 1)\n",
      "('RED REINDEER STRING OF 20 LIGHTS', 1)\n",
      "('COSY HOUR GIANT TUBE MATCHES', 2)\n",
      "('RETRO SPOT GIANT  TUBE MATCHES', 1)\n",
      "('GLITTER CHRISTMAS HEART ', 1)\n",
      "('GLITTER CHRISTMAS STAR ', 1)\n",
      "('GLITTER CHRISTMAS TREE', 1)\n",
      "('DOOR MAT 3 SMILEY CATS', 2)\n",
      "('RED SPOTTY COIR DOORMAT', 3)\n",
      "('DOORMAT HEARTS', 2)\n",
      "('SKULLS WRAP', 1)\n",
      "('MINATURE COLOURED GARDENING SET', 1)\n",
      "('GREEN BLUE FLOWER PIGGY BANK', 1)\n",
      "('PINK SPOTTY BOWL', 2)\n",
      "('RED SPOTTY BOWL', 3)\n",
      "('SET/6 RED SPOTTY PAPER CUPS', 1)\n",
      "('SET OF 6 CAKE CHOPSTICKS', 2)\n",
      "('CAMOUFLAGE LED TORCH', 2)\n",
      "('CHOCOLATE CALCULATOR', 2)\n",
      "('200 RED + WHITE BENDY STRAWS', 1)\n",
      "('I CAN ONLY PLEASE ONE PERSON MUG', 1)\n",
      "('METAL SIGN EMPIRE TEA', 2)\n",
      "('COOK WITH WINE METAL SIGN ', 2)\n",
      "('GIN + TONIC DIET METAL SIGN', 1)\n",
      "('POTTERING IN THE SHED METAL SIGN', 1)\n",
      "('\"POPCORN HOLDER ', 3)\n",
      "('SET/6 RED SPOTTY PAPER PLATES', 1)\n",
      "('SET/6 CHRISTMAS ICICLE T-LIGHTS', 1)\n",
      "('MIRROR MOSAIC T-LIGHT HOLDER ROUND', 1)\n",
      "('WHITE WITH BLACK CATS MUG', 1)\n",
      "('PAINTED METAL PEARS ASSORTED', 1)\n",
      "('RED SPOTTY CUP', 2)\n",
      "('BLUE  SPOTTY CUP', 1)\n",
      "('PINK  SPOTTY CUP', 1)\n",
      "('MAGIC GARDEN MOUNT FUJI', 1)\n",
      "('MAGIC SHEEP WOOL GROWING FROM PAPER', 1)\n",
      "('6 RIBBONS RUSTIC CHARM', 3)\n",
      "('TRADITIONAL CHRISTMAS RIBBONS', 1)\n",
      "('SCANDINAVIAN REDS RIBBONS', 2)\n",
      "('6 RIBBONS ELEGANT CHRISTMAS ', 2)\n",
      "('6 RIBBONS EMPIRE  ', 1)\n",
      "('LIGHT PINK CHERRY LIGHTS', 1)\n",
      "('BROWN FLOWER LIGHTS', 1)\n",
      "('WILLOW BRANCH LIGHTS.', 1)\n",
      "('BLUE PULL BACK RACING CAR', 1)\n",
      "('SET/6 3D KIT CARDS FOR KIDS', 3)\n",
      "('PACK OF 60 MUSHROOM CAKE CASES', 1)\n",
      "('RED SPOTS  WRAP ', 1)\n",
      "('SILVER HANGING T-LIGHT HOLDER DOME', 1)\n",
      "('RETRO SPOTS PUDDING BOWL', 1)\n",
      "('RED SPOTTY SHOPPER BAG', 1)\n",
      "('LOO ROLL  METAL SIGN ', 1)\n",
      "('PINK JUICY FRUIT PHOTO FRAME', 1)\n",
      "('RETRO SPOTS BUTTER DISH', 1)\n",
      "('WRAP BLIZZARD', 1)\n",
      "('RETRO SPOT TRADITIONAL TEAPOT ', 1)\n",
      "('RETRO SPOT SUGAR JAM BOWL', 1)\n",
      "('SET/5 RED SPOTTY LID GLASS BOWLS', 2)\n",
      "('RED SPOTTY PLATE ', 1)\n",
      "('JIGSAW TOADSTOOLS 3 PIECE', 1)\n",
      "('RETRO SPOT SMALL MILK JUG', 2)\n",
      "('RETRO SPOT MUG', 2)\n",
      "('RETRO SPOT STORAGE JAR', 3)\n",
      "('TEA CUP AND SAUCER RETRO SPOT', 1)\n",
      "('EDWARDIAN PARASOL BLACK', 1)\n",
      "('EDWARDIAN PARASOL NATURAL', 1)\n",
      "('FELT TOADSTOOL LARGE', 1)\n",
      "('FELT TOADSTOOL  SMALL', 1)\n",
      "('POLYESTER FILLER PAD 40x40cm', 1)\n",
      "('POLYESTER FILLER PAD 60x40cm', 1)\n",
      "('KIDS RAIN MAC BLUE', 2)\n",
      "('KIDS RAIN MAC PINK', 2)\n",
      "('RED SPOTTY CHILDS UMBRELLA', 1)\n",
      "('ZINC WILLIE WINKIE  CANDLE STICK', 1)\n",
      "('CREAM SWEETHEART MAGAZINE RACK', 1)\n",
      "('DOOR MAT TOPIARY', 4)\n",
      "('SWALLOWS GREETING CARD', 2)\n",
      "('SET/20 POSIES PAPER NAPKINS', 1)\n",
      "('BLUE PAISLEY NOTEBOOK', 1)\n",
      "('BLUE PAISLEY JOURNAL ', 1)\n",
      "('PENNY FARTHING BIRTHDAY CARD', 2)\n",
      "('VIPPASSPORT COVER ', 1)\n",
      "('SET/10 PINK SPOTTY PARTY CANDLES', 3)\n",
      "('SET/10 BLUE SPOTTY PARTY CANDLES', 2)\n",
      "('TROPICAL LUGGAGE TAG', 1)\n",
      "('\"WRAP', 1)\n",
      "('STRAWBERRIES PRINT BOWL', 1)\n",
      "('PACK 20 ENGLISH ROSE PAPER NAPKINS', 1)\n",
      "('TROPICAL PASSPORT COVER ', 1)\n",
      "('UNION JACK FLAG LUGGAGE TAG', 1)\n",
      "('VIP LUGGAGE TAG ', 2)\n",
      "('CHRYSANTHEMUM NOTEBOOK', 1)\n",
      "('GREEN FERN NOTEBOOK', 1)\n",
      "('ROBOT BIRTHDAY CARD', 1)\n",
      "('DINOSAUR BIRTHDAY CARD', 2)\n",
      "('MULTI HEARTS  STICKERS', 1)\n",
      "('SKULLS  WATER TRANSFER TATTOOS ', 1)\n",
      "('ROSE DU SUD CHILDS APRON', 1)\n",
      "('PINK DRESS JEWELLERY STAND ', 1)\n",
      "('BLACK STITCHED WALL CLOCK', 1)\n",
      "('RED GINGHAM ROSE JEWELLERY BOX', 1)\n",
      "('F FAIRY POTPOURRI CUSHIONS LAVENDER', 1)\n",
      "('PINK SPOTS  WRAP ', 2)\n",
      "('GREEN GINGHAM FLOWER JEWELLERY BOX', 1)\n",
      "('KENSINGTON COFFEE SET', 1)\n",
      "('OCEAN SCENT CANDLE IN JEWELLED BOX', 1)\n",
      "('ROSE SCENT CANDLE JEWELLED DRAWER', 1)\n",
      "('GLASS HONEYPOT WASP CATCHER', 1)\n",
      "('COSY HOUR CIGAR BOX MATCHES ', 1)\n",
      "('S/4 FESTIVE GREEN DINNER CANDLES', 2)\n",
      "('REX CASH+CARRY JUMBO SHOPPER', 3)\n",
      "('BRIGHT BLUES RIBBONS ', 1)\n",
      "('PACK OF 12 HEARTS DESIGN TISSUES ', 1)\n",
      "('PACK OF 12 RED SPOTTY TISSUES ', 2)\n",
      "('RECYCLED PENCIL WITH RABBIT ERASER', 1)\n",
      "('ROTATING SILVER ANGELS T-LIGHT HLDR', 2)\n",
      "('60 GOLD AND SILVER FAIRY CAKE CASES', 1)\n",
      "('STRAWBERRY SCENTED SET/9 T-LIGHTS', 1)\n",
      "('CINAMMON SET OF 9 T-LIGHTS', 2)\n",
      "('FROSTED BOX 9 WHITE T-LIGHT CANDLES', 2)\n",
      "('SMALL RETRO SPOT MUG IN BOX  WHITE', 1)\n",
      "('SMALL RETRO SPOT MUG IN BOX  RED', 2)\n",
      "('ASSTD DESIGN BUBBLE GUM RING', 1)\n",
      "('ROMANTIC PINKS RIBBONS ', 1)\n",
      "('SILVER CHRISTMAS TREE BAUBLE STAND ', 1)\n",
      "('CORONA MEXICAN TRAY', 2)\n",
      "('MILK PAN RED RETROSPOT', 1)\n",
      "('SILVER SLEIGHBELL  WREATH', 1)\n",
      "('DAIRY MAID  PUDDING BOWL', 1)\n",
      "('DAIRY MAID LARGE MILK JUG', 1)\n",
      "('FRENCH ENAMEL CANDLEHOLDER', 1)\n",
      "('JOY WOODEN BLOCK LETTERS', 2)\n",
      "('WOOLLY HAT SOCK GLOVE ADVENT STRING', 1)\n",
      "('Discount', 2)\n",
      "('LARGE CAMPHOR WOOD FIELD MUSHROOM ', 1)\n",
      "('RED STAR CARD HOLDER', 1)\n",
      "('ENGLISH ROSE GARDEN SECATEURS', 1)\n",
      "('ENGLISH ROSE TORCH', 1)\n",
      "('CHRISTMAS HANGING TREE WITH BELL', 3)\n",
      "('WHITE DOVE HONEYCOMB PAPER GARLAND', 1)\n",
      "('SET OF 12 LILY BOTANICAL T-LIGHTS', 1)\n",
      "('PINK STRIPE HOT WATER BOTTLE', 3)\n",
      "('SET/6 IVORY BIRD T-LIGHT CANDLES', 1)\n",
      "('SET/6 SILVER REINDEER T-LIGHTS', 2)\n",
      "('SET/6 BLACK SNOWFLAKE T-LIGHTS ', 1)\n",
      "('SLATE TILE NATURAL HANGING', 2)\n",
      "('RAIN HAT WITH RED SPOTS', 2)\n",
      "('WISE MAN STAR SHAPE EGG PAN', 1)\n",
      "('SET 12 KIDS COLOUR  CHALK STICKS', 1)\n",
      "('\"FEATHER DUSTER', 1)\n",
      "('CROCHET BEAR WITH BLUE STRIPES', 1)\n",
      "('SMALL SKULL WINDMILL', 1)\n",
      "('72 ROUND PINK DOILIES', 1)\n",
      "('SET OF 20 KIDS COOKIE CUTTERS', 1)\n",
      "('BLACK LOVE BIRD T-LIGHT HOLDER', 1)\n",
      "('STRAWBERRY BATH SPONGE ', 1)\n",
      "('WATERMELON BATH SPONGE', 1)\n",
      "('SANDWICH BATH SPONGE', 1)\n",
      "(\"ASS COL SMALL SAND FROG P'WEIGHT\", 2)\n",
      "('S/6 WOODEN SKITTLES IN COTTON BAG', 1)\n",
      "('SET/6 PINK BIRD T-LIGHT CANDLES', 1)\n",
      "('VANILLA INCENSE IN TIN', 1)\n",
      "('12 PENCILS SMALL TUBE RED SPOTTY', 2)\n",
      "('12 MINI TOADSTOOL PEGS', 1)\n",
      "('PHOTO CUBE', 1)\n",
      "(' 3 STRIPEY MICE FELTCRAFT', 1)\n",
      "('FELTCRAFT BUTTERFLY HEARTS', 2)\n",
      "('TOAST ITS - FAIRY FLOWER', 1)\n",
      "('TOAST ITS - DINOSAUR', 1)\n",
      "('HEARTS  STICKERS', 1)\n",
      "('WOODLAND  STICKERS', 1)\n",
      "('GLASS STAR FROSTED T-LIGHT HOLDER', 1)\n",
      "('HI TEC ALPINE HAND WARMER', 1)\n",
      "('LOVE HEART POCKET WARMER', 1)\n",
      "('ASSORTED TUTTI FRUTTI BRACELET', 2)\n",
      "('TRADITIONAL WOODEN CATCH CUP GAME ', 1)\n",
      "('QUEEN OF SKIES LUGGAGE TAG', 1)\n",
      "('MODERN FLORAL STATIONERY SET', 1)\n",
      "('SKULL SHOULDER BAG', 2)\n",
      "('WOODLAND DESIGN  COTTON TOTE BAG', 2)\n",
      "('LOLITA  DESIGN  COTTON TOTE BAG', 3)\n",
      "('SAVE THE PLANET COTTON TOTE BAG', 1)\n",
      "('JUMBO BAG OWLS', 1)\n",
      "('JUMBO BAG WOODLAND ANIMALS', 1)\n",
      "('POP ART PEN CASE & PENS', 1)\n",
      "('DINOSAUR LUNCHBOX WITH CUTLERY', 1)\n",
      "('SILVER FINCH DECORATION', 1)\n",
      "(' BLACK PIRATE TREASURE CHEST', 1)\n",
      "('SMALL CAMPHOR WOOD FIELD  MUSHROOM', 1)\n",
      "(' CAMPHOR WOOD PORTOBELLO MUSHROOM', 1)\n",
      "('PORCELAIN T-LIGHT HOLDERS ASSORTED', 2)\n",
      "('BIRD BOX CHRISTMAS TREE DECORATION', 1)\n",
      "('SET/6 BLACK GLITTER REINDEER CANDLE', 1)\n",
      "('SKULLS  DESIGN  COTTON TOTE BAG', 1)\n",
      "('LUNCH BAG  BLACK SKULL.', 1)\n",
      "('VINTAGE BILLBOARD DRINK ME MUG', 1)\n",
      "('VINTAGE BILLBOARD LOVE/HATE MUG', 1)\n",
      "('CREAM HEART CARD HOLDER', 1)\n",
      "('DOOR MAT SWEET HOME', 1)\n",
      "('DOOR MAT WELCOME PUPPIES', 1)\n",
      "('DOOR MAT ENGLISH ROSE ', 2)\n",
      "('RECIPE BOX WITH METAL HEART', 1)\n",
      "('RED FLORAL FELTCRAFT SHOULDER BAG', 1)\n",
      "('GREEN FLORAL FELTCRAFT SHOULDER BAG', 1)\n",
      "('SET 3 WICKER LOG BASKETS', 1)\n",
      "('YELLOW PURPLE DAISY FELT PURSE KIT', 1)\n",
      "('YELLOW FLOWERS FELT HANDBAG KIT', 1)\n",
      "('FRYING PAN UNION FLAG', 1)\n",
      "('LIGHT BIRD HOUSE TREE DECORATION', 1)\n",
      "('GLITTER HANGING BUTTERFLY STRING', 1)\n",
      "('ORANGE SCENTED SET/9 T-LIGHTS', 1)\n",
      "('BROWN CHECK CAT DOORSTOP ', 1)\n",
      "('4 IVORY DINNER CANDLES GOLD FLOCK', 2)\n",
      "('FLORAL FOLK STATIONERY SET', 1)\n",
      "('PINK HEART DOTS HOT WATER BOTTLE', 1)\n",
      "('GARLAND WITH STARS AND BELLS', 2)\n",
      "('GARLAND WITH HEARTS AND BELLS', 1)\n",
      "('RED WHITE SCARF  HOT WATER BOTTLE', 1)\n",
      "('\"STRING OF 8 BUTTERFLIES', 1)\n",
      "('4 IVORY DINNER CANDLES SILVER FLOCK', 1)\n",
      "('S/4 BURGUNDY WINE DINNER CANDLES', 1)\n",
      "('S/4 FESTIVE RED DINNER CANDLES', 1)\n",
      "('CAKE STAND VICTORIAN FILIGREE MED', 1)\n",
      "('RED HANGING METAL STAR TLIGHT HLDR', 1)\n",
      "('SET OF KITCHEN WALL  STICKERS', 1)\n",
      "('SET/4 PINK ORCHID CANDLES IN BOWL', 1)\n",
      "('SET/4 BLUE FLOWER CANDLES IN BOWL', 1)\n",
      "('FUNKY MONKEY MUG', 1)\n",
      "('BIG DOUGHNUT FRIDGE MAGNETS', 1)\n",
      "('FLORAL ELEPHANT SOFT TOY', 1)\n",
      "('SLEEPING CAT ERASERS', 1)\n",
      "('BLACK AND WHITE PAISLEY FLOWER MUG', 1)\n",
      "('SET/20 RED SPOTTY PAPER NAPKINS ', 1)\n",
      "('PACK OF 12 SKULL TISSUES', 1)\n",
      "('BIRD HOUSE HOT WATER BOTTLE', 1)\n",
      "('WIRE FLOWER T-LIGHT HOLDER', 1)\n",
      "('ASSORTED FRAGRANCE BATH CONFETTI', 1)\n",
      "('PLACE SETTING WHITE STAR', 1)\n",
      "('PREMIUM CHURCH CANDLE', 1)\n",
      "('RIBBON REEL FLORA + FAUNA ', 1)\n",
      "('RIBBON REEL HEARTS DESIGN ', 1)\n",
      "('ABSTRACT CIRCLES POCKET BOOK', 1)\n",
      "('GREEN FERN POCKET BOOK', 1)\n",
      "('SET OF 6 GIRLS CELEBRATION CANDLES', 1)\n",
      "('SET 6 FOOTBALL CELEBRATION CANDLES', 1)\n",
      "('MIRROR MOSAIC T-LIGHT HOLDER ', 1)\n",
      "('SMALL FOLKART CHRISTMAS TREE DEC', 1)\n",
      "('SMALL FOLKART STAR CHRISTMAS DEC', 1)\n",
      "('SMALLFOLKART BAUBLE CHRISTMAS DEC', 1)\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as pipe1:\n",
    "    ip1 = (\n",
    "        pipe1\n",
    "        |beam.io.ReadFromText('./online_retail_mini.csv', skip_header_lines=True)\n",
    "        |beam.Map(lambda x: x.split(\",\"))\n",
    "        |beam.Map(lambda x: (x[2], x))\n",
    "        |beam.combiners.Count.PerKey()\n",
    "        |beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate with Multiple Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UPI,Narendra', 2)\n",
      "('Cash,Amit', 1)\n",
      "('UPI,Smriti', 1)\n",
      "('UPI,Nitish', 1)\n",
      "('Cash,Deependra', 1)\n",
      "('UPI,Jaishankar', 1)\n",
      "('Cash,Sukanta', 1)\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as pipe1:\n",
    "    ip1 = (\n",
    "        pipe1\n",
    "        |beam.io.ReadFromText('./Cust.csv', skip_header_lines=True)\n",
    "        |beam.Map(lambda x: x.split(\",\"))\n",
    "        |beam.Map(lambda x: (x[3] + \",\" + x[1], x))\n",
    "        |beam.combiners.Count.PerKey()\n",
    "        |beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Per Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UPI,Narendra', 800)\n",
      "('Cash,Amit', 0)\n",
      "('UPI,Smriti', 0)\n",
      "('UPI,Nitish', 300)\n",
      "('Cash,Deependra', 0)\n",
      "('UPI,Jaishankar', 500)\n",
      "('Cash,Sukanta', 400)\n"
     ]
    }
   ],
   "source": [
    "def sum_val_filter(element):\n",
    "    if sum(element) >= 300:\n",
    "        return sum(element)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "with beam.Pipeline() as pipe1:\n",
    "    ip1 = (\n",
    "        pipe1\n",
    "        |beam.io.ReadFromText('./Cust.csv', skip_header_lines=True)\n",
    "        |beam.Map(lambda x: x.split(\",\"))\n",
    "        |beam.Map(lambda x: (x[3] + \",\" + x[1], int(x[2])))\n",
    "        |beam.CombinePerKey(sum_val_filter)\n",
    "        |beam.Map(print)\n",
    "    )\n",
    "\n",
    "# ('UPI,Narendra', 100)\n",
    "# ('Cash,Amit', 200)\n",
    "# ('UPI,Smriti', 150)\n",
    "# ('UPI,Nitish', 300)\n",
    "# ('Cash,Deependra', 250)\n",
    "# ('UPI,Jaishankar', 500)\n",
    "# ('Cash,Sukanta', 400)\n",
    "# ('UPI,Narendra', 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UPI,Narendra', 800)\n",
      "('Cash,Amit', 0)\n",
      "('UPI,Smriti', 0)\n",
      "('UPI,Nitish', 0)\n",
      "('Cash,Deependra', 0)\n",
      "('UPI,Jaishankar', 500)\n",
      "('Cash,Sukanta', 0)\n"
     ]
    }
   ],
   "source": [
    "# Pass arg to function\n",
    "def sum_val_filter(element, max_val):\n",
    "    if sum(element) >= max_val:\n",
    "        return sum(element)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "with beam.Pipeline() as pipe1:\n",
    "    ip1 = (\n",
    "        pipe1\n",
    "        |beam.io.ReadFromText('./Cust.csv', skip_header_lines=True)\n",
    "        |beam.Map(lambda x: x.split(\",\"))\n",
    "        |beam.Map(lambda x: (x[3] + \",\" + x[1], int(x[2])))\n",
    "        |beam.CombinePerKey(sum_val_filter, 500)\n",
    "        |beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with beam.Pipeline() as pipe1:\n",
    "    ip1 = (\n",
    "        pipe1\n",
    "        |beam.io.ReadFromText('./Cust.csv', skip_header_lines=True)\n",
    "        |beam.Map(lambda x: x.split(\",\"))\n",
    "        |beam.Filter(lambda x: int(x[2])<=200)\n",
    "        |beam.io.WriteToText(\"./Cust_out.csv\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ReadFromText\n",
    "* Map\n",
    "* Filter\n",
    "* CombinePerKey\n",
    "* combiners.Count.PerKey()\n",
    "* combiners.Count.Globally()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composite Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n",
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    }
   ],
   "source": [
    "def Filter_trans_type(trans, input_elem):\n",
    "    return input_elem[3] == trans \n",
    "\n",
    "def cap(elem):\n",
    "    return elem[0], elem[1].title(), elem[2], elem[3]\n",
    "\n",
    "def key_val(elem):\n",
    "    return elem[3], elem[1] + \",\" + str(elem[2])\n",
    "\n",
    "with beam.Pipeline() as pipe:\n",
    "    input_collection = (\n",
    "        pipe\n",
    "        |beam.io.ReadFromText('./Cust.csv', skip_header_lines=True)\n",
    "        |beam.Map(lambda x: x.split(\",\"))\n",
    "    )\n",
    "\n",
    "    UPI = (\n",
    "        input_collection\n",
    "        |beam.Filter(lambda record: Filter_trans_type('UPI', record))\n",
    "        |\"Capitalize the UPI customer names\" >> beam.Map(cap)\n",
    "        |\"Generating Key value pairs for UPI\" >> beam.Map(key_val)\n",
    "        |\"Write UPI results to file\" >> beam.io.WriteToText(\"./UPI_Result\")\n",
    "    )\n",
    "\n",
    "    CASH = (\n",
    "        input_collection\n",
    "        |beam.Filter(lambda record: Filter_trans_type('Cash', record))\n",
    "        |\"Capitalize the CASH customer name\" >> beam.Map(cap)\n",
    "        |\"Generating Key value pairs for CASH\" >> beam.Map(key_val)\n",
    "        |\"Write Cash results to file\" >> beam.io.WriteToText(\"./Cash_Result\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTransform(beam.PTransform):\n",
    "    def expand(self, input_col):\n",
    "        a = (\n",
    "            input_col\n",
    "            |\"capital\" >> beam.Map(cap)\n",
    "            |\"key val\" >> beam.Map(key_val)\n",
    "        )\n",
    "        return a\n",
    "\n",
    "with beam.Pipeline() as pipe:\n",
    "    input_collection = (\n",
    "        pipe\n",
    "        |beam.io.ReadFromText('./Cust.csv', skip_header_lines=True)\n",
    "        |beam.Map(lambda x: x.split(\",\"))\n",
    "    )\n",
    "\n",
    "    UPI = (\n",
    "        input_collection\n",
    "        |beam.Filter(lambda record: Filter_trans_type('UPI', record))\n",
    "        |\"My Transformation for UPI\" >> MyTransform()\n",
    "        |\"Write UPI results to file\" >> beam.io.WriteToText(\"./new_UPI_Result\")\n",
    "    )\n",
    "\n",
    "    CASH = (\n",
    "        input_collection\n",
    "        |beam.Filter(lambda record: Filter_trans_type('Cash', record))\n",
    "        |\"My Transformation for Cash\" >> MyTransform()\n",
    "        |\"Write Cash results to file\" >> beam.io.WriteToText(\"./new_Cash_Result\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParDo\n",
    "\n",
    "Every item is processed independently of the other ones. It is a stateless implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitRow(beam.DoFn):\n",
    "    def process(self, elem):\n",
    "        customer = elem.split(\",\")\n",
    "        # return [customer]   # Pardo always returns a list\n",
    "        yield customer\n",
    "\n",
    "class key_val(beam.DoFn):\n",
    "    def process(self, elem):\n",
    "        return [(elem[3] + \",\" + elem[1] , int(elem[2]))]\n",
    "    \n",
    "class cap(beam.DoFn):\n",
    "    def process(self, elem):\n",
    "        return [(elem[0], elem[1].title(), elem[2], elem[3])]\n",
    "    \n",
    "class filter(beam.DoFn):\n",
    "    def process(self, elem):\n",
    "        if elem[3] == 'Cash':\n",
    "            return [elem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cash,Amit', 300)\n",
      "('Cash,Deependra', 450)\n",
      "('Cash,Sukanta', 400)\n",
      "('Cash,Nitish', 600)\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as pipe:\n",
    "    ip = (\n",
    "        pipe\n",
    "        |beam.io.ReadFromText('./Cust.csv', skip_header_lines=True)\n",
    "        |beam.ParDo(SplitRow())\n",
    "        |beam.ParDo(cap())\n",
    "        |beam.ParDo(filter())\n",
    "        |beam.ParDo(key_val())\n",
    "        |beam.CombinePerKey(sum)\n",
    "        |beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Side Input\n",
    "Passing additional arguments in addition to existing arguments to a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UPI,Narendra', 800)\n",
      "('Cash,Amit', 0)\n",
      "('UPI,Smriti', 0)\n",
      "('UPI,nitish', 700)\n",
      "('Cash,Deependra', 0)\n",
      "('UPI,Jaishankar', 500)\n",
      "('Cash,Sukanta', 0)\n",
      "('UPI,Deependra', 1600)\n",
      "('Cash,nitish', 600)\n",
      "('UPI,Amit', 0)\n",
      "('Cash,deependra', 0)\n"
     ]
    }
   ],
   "source": [
    "def sum_val_filter(element, max_val):\n",
    "    if sum(element) >= max_val:\n",
    "        return sum(element)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "with beam.Pipeline() as pipe1:\n",
    "    ip1 = (\n",
    "        pipe1\n",
    "        |beam.io.ReadFromText('./Cust.csv', skip_header_lines=True)\n",
    "        |beam.Map(lambda x: x.split(\",\"))\n",
    "        |beam.Map(lambda x: (x[3] + \",\" + x[1], int(x[2])))\n",
    "        |beam.CombinePerKey(sum_val_filter, 1500)\n",
    "        |beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Side Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class filters(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        if element[3] == 'Cash':\n",
    "            yield element\n",
    "        if element[3] == 'UPI':\n",
    "            yield beam.pvalue.TaggedOutput('upi', element)\n",
    "\n",
    "with beam.Pipeline() as pipe:\n",
    "    ip = pipe | beam.io.ReadFromText('./Cust.csv', skip_header_lines=True)\n",
    "    out = ip | beam.ParDo(SplitRow()) | beam.ParDo(filters()).with_outputs('upi', main='cash')\n",
    "    cash1 = out.cash \n",
    "    upi = out.upi\n",
    "    upi | \"Writing to UPI file\" >> beam.io.WriteToText(\"upi\")\n",
    "    cash1 | \"Writing to Cash file\" >> beam.io.WriteToText(\"cash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Outputs : PCollection[[3]: Map(print).None]\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam \n",
    "inputs = [0,1,2,3]\n",
    "\n",
    "with beam.Pipeline() as pipeline:\n",
    "    outputs = (\n",
    "        pipeline\n",
    "        | beam.Create(inputs)\n",
    "        | beam.Map(print)\n",
    "    )\n",
    "\n",
    "print(f\"Outputs : {outputs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as pipeline:\n",
    "    outputs = (\n",
    "        pipeline\n",
    "        | \"Create a pipeline\" >> beam.Create(inputs)\n",
    "        | \"Multiplying each element by 100\" >> beam.Map(lambda x:x*100)\n",
    "        | beam.Map(print)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FlatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "inputs = [1,2,3,4]\n",
    "with beam.Pipeline() as pipeline:\n",
    "    outputs = (\n",
    "        pipeline\n",
    "        | \"Create a pipeline\" >> beam.Create(inputs)\n",
    "        | \"Repeating every element that many times and flattening out\" >> beam.FlatMap(lambda x: [x for i in range(x)])\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter: One to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as pipeline:\n",
    "    outputs = (\n",
    "        pipeline\n",
    "        | \"Create a pipeline\" >> beam.Create(inputs)\n",
    "        | \"Keep only even numbers\" >> beam.Filter(lambda x:x%2==0)\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "inputs = [1,2,3,4,5,6]\n",
    "with beam.Pipeline() as pipeline:\n",
    "    outputs = (\n",
    "        pipeline\n",
    "        | \"Create a pipeline\" >> beam.Create(inputs)\n",
    "        | \"Sum all the values together\" >> beam.CombineGlobally(sum)\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce \n",
    "x = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "reduce(lambda x,y : x + y,x,0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GroupByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('WB', ['Paddy', 'Jute'])\n",
      "('Assam', ['Tea'])\n",
      "('Karnataka', ['Coffee', 'Coconut'])\n",
      "('Hyderabad', ['Chilly'])\n"
     ]
    }
   ],
   "source": [
    "inputs = [\n",
    "    ('WB', 'Paddy'),\n",
    "    ('Assam', 'Tea'),\n",
    "    ('WB', 'Jute'),\n",
    "    ('Karnataka', \"Coffee\"),\n",
    "    ('Hyderabad', 'Chilly'),\n",
    "    ('Karnataka', 'Coconut')\n",
    "]\n",
    "with beam.Pipeline() as pipeline:\n",
    "    outputs = (\n",
    "        pipeline\n",
    "        | \"Create a pipeline\" >> beam.Create(inputs)\n",
    "        | \"Grouping states by produce\" >> beam.GroupByKey()\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as pipeline:\n",
    "\ttotal_elements = (\n",
    "\t\tpipeline\n",
    "\t\t| 'Create fruits' >> beam.Create(\n",
    "\t\t\t['mango', 'apple', 'avocado', 'papaya', 'mango', 'pineapple', 'guava', 'banana', 'avocado', 'strawberry', 'banana']\n",
    "\t\t\t)\n",
    "\t\t| 'Count unique elements' >> beam.Distinct()\n",
    "\t\t|beam.combiners.Count.Globally()\n",
    "\t\t| beam.Map(print)\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hibiscus\n",
      "Rose\n",
      "Lotus\n",
      "Tomato\n",
      "Blueberry.\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam \n",
    "\n",
    "with beam.Pipeline() as pipeline:\n",
    "    plants = (\n",
    "        pipeline \n",
    "        | beam.Create([\n",
    "            ' Hibiscus',\n",
    "            'Rose ',\n",
    "            'Lotus\\n',\n",
    "            'Tomato  ',\n",
    "            'Blueberry.'\n",
    "        ])\n",
    "        | beam.Map(str.strip)\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hibiscus\n",
      "Rose\n",
      "Lotus\n",
      "Tomato\n",
      "Blueberry\n"
     ]
    }
   ],
   "source": [
    "def do_str_strip(element):\n",
    "    return element.strip('. \\n')\n",
    "\n",
    "with beam.Pipeline() as pipeline:\n",
    "    plants = (\n",
    "        pipeline \n",
    "        | beam.Create([\n",
    "            ' Hibiscus',\n",
    "            'Rose ',\n",
    "            'Lotus\\n',\n",
    "            'Tomato  ',\n",
    "            'Blueberry.'\n",
    "        ])\n",
    "        | beam.Map(do_str_strip)\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with beam.Pipeline() as pipeline:\n",
    "    plants = (\n",
    "        pipeline \n",
    "        | beam.Create([\n",
    "            ' Hibiscus',\n",
    "            'Rose ',\n",
    "            'Lotus\\n',\n",
    "            'Tomato  ',\n",
    "            'Blueberry.'\n",
    "        ])\n",
    "        | beam.Map(lambda x : x.strip())\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hibiscus', ' Rose ', ' Lotus', ' Tomato', ' Blueberry']\n"
     ]
    }
   ],
   "source": [
    "def do_str_strip(element):\n",
    "    return element.strip('. \\n')\n",
    "\n",
    "with beam.Pipeline() as pipeline:\n",
    "    plants = (\n",
    "        pipeline \n",
    "        | beam.Create([\n",
    "            ' Hibiscus, Rose , Lotus, Tomato, Blueberry.'\n",
    "        ])\n",
    "        | beam.Map(do_str_strip)\n",
    "        | beam.Map(lambda x: x.split(\",\"))\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hibiscus', ' Rose ', ' Lotus']\n",
      "['Tomato', ' Blueberry']\n"
     ]
    }
   ],
   "source": [
    "def do_str_strip(element):\n",
    "    return element.strip('. \\n')\n",
    "\n",
    "with beam.Pipeline() as pipeline:\n",
    "    plants = (\n",
    "        pipeline \n",
    "        | beam.Create([\n",
    "            ' Hibiscus, Rose , Lotus', \n",
    "            'Tomato, Blueberry.'\n",
    "        ])\n",
    "        | beam.Map(do_str_strip)\n",
    "        | beam.Map(lambda x: x.split(\",\"))\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n        if (typeof window.interactive_beam_jquery == 'undefined') {\n          var jqueryScript = document.createElement('script');\n          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n          jqueryScript.type = 'text/javascript';\n          jqueryScript.onload = function() {\n            var datatableScript = document.createElement('script');\n            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n            datatableScript.type = 'text/javascript';\n            datatableScript.onload = function() {\n              window.interactive_beam_jquery = jQuery.noConflict(true);\n              window.interactive_beam_jquery(document).ready(function($){\n                \n              });\n            }\n            document.head.appendChild(datatableScript);\n          };\n          document.head.appendChild(jqueryScript);\n        } else {\n          window.interactive_beam_jquery(document).ready(function($){\n            \n          });\n        }"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple --> 10\n",
      "Mango --> 20\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "with beam.Pipeline() as pipeline:\n",
    "    plants = (\n",
    "        pipeline \n",
    "        | beam.Create([\n",
    "            (10, 'Apple'),\n",
    "            (20, 'Mango')\n",
    "        ])\n",
    "        | beam.MapTuple(lambda x, y: f'{y} --> {x}')\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FlatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hibiscus\n",
      "Rose\n",
      "Lotus\n",
      "Tomato\n",
      "Blueberry\n"
     ]
    }
   ],
   "source": [
    "def do_str_strip(element):\n",
    "    return element.strip('. \\n')\n",
    "\n",
    "with beam.Pipeline() as pipeline:\n",
    "    plants = (\n",
    "        pipeline \n",
    "        | beam.Create([\n",
    "            ' Hibiscus, Rose , Lotus', \n",
    "            'Tomato, Blueberry.'\n",
    "        ])\n",
    "        \n",
    "        | beam.FlatMap(lambda x: x.split(\",\"))\n",
    "        | beam.Map(do_str_strip)\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as pipeline:\n",
    "    plants = (\n",
    "        pipeline \n",
    "        | beam.Create([\n",
    "            1,2,3,4,5\n",
    "        ])\n",
    "        | beam.Filter(lambda x: x%2 == 0)\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three\n",
      "Four\n",
      "Five\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as pipeline:\n",
    "    plants = (\n",
    "        pipeline \n",
    "        | beam.Create([\n",
    "            \"One\", \"Two\", \"Three\", \"Four\", \"Five\"\n",
    "        ])\n",
    "        | beam.Filter(lambda x: len(x) >= 4)\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UPI', 3850)\n",
      "('Cash', 1750)\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as pipeline:\n",
    "    plants = (\n",
    "        pipeline \n",
    "        | beam.io.ReadFromText('Cust.csv', skip_header_lines=True)\n",
    "        | beam.Map(lambda x: x.split(\",\"))\n",
    "        # | beam.Filter(lambda x: x[3]=='Cash')\n",
    "        | beam.Map(lambda x: (x[3], int(x[2])))\n",
    "        | beam.CombinePerKey(sum)\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParDo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One', ' Two', ' Three', ' Four', ' Five']\n"
     ]
    }
   ],
   "source": [
    "class SplitWords(beam.DoFn):\n",
    "    def __init__(self, delimiter=','):\n",
    "        self.delimiter = delimiter \n",
    "    \n",
    "    def process(self, element):\n",
    "        yield element.split(self.delimiter)      # Recommended\n",
    "        # return [element.split(self.delimiter)]   # Not recommended\n",
    "\n",
    "with beam.Pipeline() as pipeline:\n",
    "    plants = (\n",
    "        pipeline \n",
    "        | beam.Create([\n",
    "            \"One, Two, Three, Four, Five\"\n",
    "        ])\n",
    "        | beam.ParDo(SplitWords())\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['123', 'Narendra', '100', 'UPI']\n",
      "['125', 'Smriti', '150', 'UPI']\n",
      "['222', 'nitish', '300', 'UPI']\n",
      "['444', 'Jaishankar', '500', 'UPI']\n",
      "['123', 'Narendra', '700', 'UPI']\n",
      "['222', 'nitish', '400', 'UPI']\n",
      "['128', 'Deependra', '1600', 'UPI']\n",
      "['124', 'Amit', '100', 'UPI']\n"
     ]
    }
   ],
   "source": [
    "class SplitRow(beam.DoFn):\n",
    "    def __init__(self, delimiter=','):\n",
    "        self.delimiter = delimiter \n",
    "    \n",
    "    def process(self, element):\n",
    "        yield element.split(self.delimiter) \n",
    "\n",
    "class FilterUPI(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        if (element[3]=='UPI'):\n",
    "            yield element \n",
    "\n",
    "with beam.Pipeline() as pipeline:\n",
    "    plants = (\n",
    "        pipeline \n",
    "        | beam.io.ReadFromText('Cust.csv', skip_header_lines=True)\n",
    "        | beam.ParDo(SplitRow())\n",
    "        | beam.ParDo(FilterUPI())\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GroupByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Carnivores,2, ['Tiger', 'Lion'])\n",
      "(Herbivores,3, ['Rabbit', 'Kangaroo', 'Guineapig'])\n",
      "(Omnivores,1, ['Comodo Dragon'])\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as pipeline:\n",
    "    plants = (\n",
    "        pipeline \n",
    "        | beam.Create([\n",
    "            ('Carnivores', 'Tiger'),\n",
    "            ('Herbivores', 'Rabbit' ),\n",
    "            ('Omnivores', 'Comodo Dragon'),\n",
    "            ('Carnivores', 'Lion' ),\n",
    "            ('Herbivores', 'Kangaroo' ),\n",
    "            ('Herbivores', 'Guineapig' ),\n",
    "        ])\n",
    "        | beam.GroupByKey()\n",
    "        | beam.MapTuple(lambda x,y : f'({x},{len(y)}, {y})')\n",
    "        # | beam.combiners.Count.PerKey()\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoGroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Subir', (['Software', 'Businessman'], ['Wanderer']))\n",
      "('Kalyani', (['Freelancer'], ['Artist', 'Vlogger']))\n",
      "('Bob', ([], ['Photographer']))\n",
      "('Alex', (['Gamer'], []))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x16c196190>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = [\n",
    "    ('Subir', 'Software'),\n",
    "    ('Kalyani', 'Freelancer'),\n",
    "    ('Subir', 'Businessman'),\n",
    "    ('Alex', 'Gamer')\n",
    "]\n",
    "\n",
    "passion = [\n",
    "    ('Subir', 'Wanderer'),\n",
    "    ('Kalyani', 'Artist'),\n",
    "    ('Kalyani', 'Vlogger'),\n",
    "    ('Bob', 'Photographer')\n",
    "]\n",
    "\n",
    "p = beam.Pipeline()\n",
    "pc_jobs = p | \"Jobs pcollection\" >> beam.Create(jobs)\n",
    "pc_passion = p | \"Passion pcollection\" >> beam.Create(passion)\n",
    "(pc_jobs, pc_passion) | beam.CoGroupByKey() | beam.Map(print)\n",
    "\n",
    "p.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregations Per Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count per key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UPI', 8)\n",
      "('Cash', 6)\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as pipeline:\n",
    "    plants = (\n",
    "        pipeline \n",
    "        | beam.io.ReadFromText('Cust.csv', skip_header_lines=True)\n",
    "        | beam.Map(lambda x: x.split(\",\"))\n",
    "        | beam.Map(lambda x: (x[3], int(x[2])))\n",
    "        | beam.combiners.Count.PerKey()\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CombinePerKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('UPI', 3850)\n",
      "('Cash', 1750)\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as pipeline:\n",
    "    plants = (\n",
    "        pipeline \n",
    "        | beam.io.ReadFromText('Cust.csv', skip_header_lines=True)\n",
    "        | beam.Map(lambda x: x.split(\",\"))\n",
    "        | beam.Map(lambda x: (x[3], int(x[2])))\n",
    "        | beam.CombinePerKey(sum)\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CombineGlobally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5600\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as pipeline:\n",
    "    plants = (\n",
    "        pipeline \n",
    "        | beam.io.ReadFromText('Cust.csv', skip_header_lines=True)\n",
    "        | beam.Map(lambda x: x.split(\",\"))\n",
    "        | beam.Map(lambda x:  int(x[2]))\n",
    "        | beam.CombineGlobally(sum)\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n",
      "36\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "with beam.Pipeline() as pipeline:\n",
    "    mcf = (\n",
    "        pipeline\n",
    "        | beam.Create([(1,2,3,4,5,6,7)])\n",
    "        | beam.FlatMap(lambda x: x)\n",
    "        | beam.Map(lambda x: x**2)\n",
    "        # | beam.CombineGlobally(sum)\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "def list_join(element):\n",
    "    res_list = []\n",
    "    for l in element:\n",
    "        # print(l)\n",
    "        res_list = res_list + l \n",
    "    return res_list\n",
    "\n",
    "with beam.Pipeline() as pipeline:\n",
    "    mcf = (\n",
    "        pipeline\n",
    "        | beam.Create([\n",
    "            [1,2,3,4,5,6,7],\n",
    "            [8,9,10]\n",
    "                       ])\n",
    "        | beam.CombineGlobally(list_join)\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timestamp by processing time\n",
    "* beam.DoFn.TimestampParam binds the timestamp info as an `apache_beam.utils.timestamp.Timestamp` object.\n",
    "* beam.DoFn.WindowParam binds the window info as an appropriate `apache_beam.transforms.window.*Window` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30 15:55:57.954463 - Strawberry\n",
      "2024-07-30 15:55:57.954613 - Blueberry\n",
      "2024-07-30 15:55:57.954645 - Raspberry\n",
      "2024-07-30 15:55:57.954672 - Cherry\n",
      "2024-07-30 15:55:57.954698 - Avocado\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam \n",
    "import time \n",
    "\n",
    "class GetTimestamp(beam.DoFn):\n",
    "    def process(self, plant, timestamp=beam.DoFn.TimestampParam):\n",
    "        yield f\"{timestamp.to_utc_datetime()} - {plant['name']}\"\n",
    "\n",
    "with beam.Pipeline() as pipeline:\n",
    "    plant_processing_times = (\n",
    "        pipeline \n",
    "        | beam.Create(\n",
    "            [\n",
    "                {'name' : 'Strawberry'},\n",
    "                {'name' : 'Blueberry'},\n",
    "                {'name' : 'Raspberry'},\n",
    "                {'name' : 'Cherry'},\n",
    "                {'name' : 'Avocado'}\n",
    "            ]\n",
    "        )\n",
    "        | beam.Map(lambda plant: beam.window.TimestampedValue(plant, time.time()))\n",
    "        | beam.ParDo(GetTimestamp())\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# timestamp\n",
      "type(timestamp) -> <class 'apache_beam.utils.timestamp.Timestamp'>\n",
      "timestamp.micros() -> 1584675660000000\n",
      "timestamp.to_rfc3339() -> '2020-03-20T03:41:00Z'\n",
      "timestamp.to_utc_datetime() -> datetime.datetime(2020, 3, 20, 3, 41)\n",
      "\n",
      "#Window\n",
      "type(window) -> <class 'apache_beam.transforms.window.IntervalWindow'>\n",
      "window.start -> Timestamp(1584675660) (2020-03-20 03:41:00)\n",
      "window.end -> Timestamp(1584675690) (2020-03-20 03:41:30)\n",
      "window.max_timestamp() -> Timestamp(1584675689.999999) (2020-03-20 03:41:29.999999)\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam \n",
    "\n",
    "class AnalyzeElement(beam.DoFn):\n",
    "    def process(self, elem, timestamp=beam.DoFn.TimestampParam, window=beam.DoFn.WindowParam):\n",
    "        yield '\\n'.join([\n",
    "            '# timestamp',\n",
    "            'type(timestamp) -> ' + repr(type(timestamp)),\n",
    "            'timestamp.micros() -> ' + repr(timestamp.micros),\n",
    "            'timestamp.to_rfc3339() -> ' + repr(timestamp.to_rfc3339()),\n",
    "            'timestamp.to_utc_datetime() -> ' + repr(timestamp.to_utc_datetime()),\n",
    "            '',\n",
    "            '#Window',\n",
    "            'type(window) -> ' + repr(type(window)),\n",
    "            'window.start -> {} ({})'.format(window.start, window.start.to_utc_datetime()),\n",
    "            'window.end -> {} ({})'.format(window.end, window.end.to_utc_datetime()),\n",
    "            'window.max_timestamp() -> {} ({})'.format(window.max_timestamp(), window.max_timestamp().to_utc_datetime()),\n",
    "        ])\n",
    "\n",
    "with beam.Pipeline() as pipeline:\n",
    "    dofn_params = (\n",
    "        pipeline\n",
    "        | beam.Create([':)'])\n",
    "        | beam.Map(lambda elem: beam.window.TimestampedValue(elem, 1584675660))\n",
    "        | beam.WindowInto(beam.window.FixedWindows(30))\n",
    "        | beam.ParDo(AnalyzeElement())\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event Time Windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Andy', 7)\n",
      "('Andy', 4)\n",
      "('Sam', 3)\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam \n",
    "from apache_beam.transforms.window import (\n",
    "    TimestampedValue,\n",
    "    Sessions,\n",
    "    Duration\n",
    ")\n",
    "from apache_beam.io.textio import WriteToText\n",
    "\n",
    "class AddTimestampDoFn(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        unix_timestamp = element[\"timestamp\"]\n",
    "        element = (element[\"userId\"], element[\"click\"])\n",
    "        yield TimestampedValue(element, unix_timestamp)\n",
    "\n",
    "with beam.Pipeline() as p:\n",
    "    events = (\n",
    "        p\n",
    "        | beam.Create([\n",
    "            {\"userId\" : \"Andy\", \"click\" : 2, \"timestamp\": 1603112520},\n",
    "            {\"userId\" : \"Sam\", \"click\" : 3, \"timestamp\": 1603113240},\n",
    "            {\"userId\" : \"Andy\", \"click\" : 4, \"timestamp\": 1603115820},\n",
    "            {\"userId\" : \"Andy\", \"click\" : 5, \"timestamp\": 1603113600},\n",
    "        ])\n",
    "    )\n",
    "    timestamped_events = events | beam.ParDo(AddTimestampDoFn())\n",
    "    windowed_events = timestamped_events | beam.WindowInto(\n",
    "        Sessions(gap_size=30 * 60),\n",
    "        trigger=None,\n",
    "        accumulation_mode=None,\n",
    "        timestamp_combiner=None,\n",
    "        allowed_lateness=Duration(seconds=1 * 24 * 60 * 60),\n",
    "    )\n",
    "\n",
    "    sum_clicks = windowed_events | beam.CombinePerKey(sum)\n",
    "    sum_clicks | beam.Map(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-20 07:37:00 - March Equinox 2021\n",
      "2021-04-27 02:31:00 - Super Full Moon\n",
      "2021-05-11 17:59:00 - Micro new Moon\n",
      "2021-05-26 10:13:00 - Super Full Moon, total lunar eclipse\n",
      "2021-06-21 02:32:00 - June Solstice 2021\n",
      "2021-08-22 11:01:00 - September Equinox 2021\n",
      "2021-09-22 18:21:00 - Super new moon\n",
      "2021-11-19 07:57:00 - Micro full moon, partial lunar eclipse\n",
      "2021-12-04 06:43:00 - Super new Moon\n",
      "2021-12-18 15:35:00 - Micro full moon\n",
      "2021-12-21 14:59:00 - December Solstice 2021\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "class GetTimestamp(beam.DoFn):\n",
    "    def process(self, event, timestamp=beam.DoFn.TimestampParam):\n",
    "        yield f\"{timestamp.to_utc_datetime()} - {event}\"\n",
    "\n",
    "def to_unix_time(time_str: str, time_format='%Y-%m-%d %H:%M:%S') -> int:\n",
    "    time_tuple = time.strptime(time_str, time_format)\n",
    "    return int(time.mktime(time_tuple))\n",
    "\n",
    "@beam.ptransform_fn\n",
    "@beam.typehints.with_input_types(beam.pvalue.PBegin)\n",
    "@beam.typehints.with_output_types(beam.window.TimestampedValue)\n",
    "def AstronomicalEvents(pipeline):\n",
    "    return (\n",
    "        pipeline \n",
    "        | beam.Create([\n",
    "            ('2021-03-20 03:37:00', 'March Equinox 2021'),\n",
    "            ('2021-04-26 22:31:00', 'Super Full Moon'),\n",
    "            ('2021-05-11 13:59:00', 'Micro new Moon'),\n",
    "            ('2021-05-26 06:13:00', 'Super Full Moon, total lunar eclipse'),\n",
    "            ('2021-06-20 22:32:00', 'June Solstice 2021'),\n",
    "            ('2021-08-22 07:01:00', 'September Equinox 2021'),\n",
    "            ('2021-09-22 14:21:00', 'Super new moon'),\n",
    "            ('2021-11-19 02:57:00', 'Micro full moon, partial lunar eclipse'),\n",
    "            ('2021-12-04 01:43:00', 'Super new Moon'),\n",
    "            ('2021-12-18 10:35:00', 'Micro full moon'),\n",
    "            ('2021-12-21 09:59:00', 'December Solstice 2021')\n",
    "        ])\n",
    "        | beam.MapTuple(\n",
    "            lambda timestamp, element: beam.window.TimestampedValue(element, to_unix_time(timestamp))\n",
    "        )\n",
    "    )\n",
    "\n",
    "with beam.Pipeline() as pipeline:\n",
    "    (\n",
    "        pipeline \n",
    "        | AstronomicalEvents()\n",
    "        | beam.ParDo(GetTimestamp())\n",
    "        | beam.Map(print)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam \n",
    "\n",
    "def human_readable_window(window) -> str:\n",
    "    if isinstance(window, beam.window.GlobalWindow):\n",
    "        return str(window)\n",
    "    return f'{window.start.to_utc_datetime()} - {window.end.to_utc_datetime()}'\n",
    "\n",
    "class PrintElementInfo(beam.DoFn):\n",
    "    def process(self, element, timestamp=beam.DoFn.TimestampParam, window=beam.DoFn.WindowParam):\n",
    "        print(f\"[{human_readable_window(window)}] {timestamp.to_utc_datetime()} -- {element}\")\n",
    "\n",
    "@beam.ptransform_fn\n",
    "def PrintWindowInfo(pcollection):\n",
    "    class PrintCountsInfo(beam.DoFn):\n",
    "        def process(self, num_elements, window=beam.DoFn.WindowParam):\n",
    "            print(f\">> Window[{human_readable_window(window)}] has {num_elements} elements.\")\n",
    "            yield num_elements\n",
    "\n",
    "    return (\n",
    "        pcollection\n",
    "        | 'Count elements per window' >> beam.combiners.Count.Globally().without_defaults()\n",
    "        | 'Print counts info' >> beam.ParDo(PrintCountsInfo())\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GlobalWindow] 2021-03-20 07:37:00 -- March Equinox 2021\n",
      "[GlobalWindow] 2021-04-27 02:31:00 -- Super Full Moon\n",
      "[GlobalWindow] 2021-05-11 17:59:00 -- Micro new Moon\n",
      "[GlobalWindow] 2021-05-26 10:13:00 -- Super Full Moon, total lunar eclipse\n",
      "[GlobalWindow] 2021-06-21 02:32:00 -- June Solstice 2021\n",
      "[GlobalWindow] 2021-08-22 11:01:00 -- September Equinox 2021\n",
      "[GlobalWindow] 2021-09-22 18:21:00 -- Super new moon\n",
      "[GlobalWindow] 2021-11-19 07:57:00 -- Micro full moon, partial lunar eclipse\n",
      "[GlobalWindow] 2021-12-04 06:43:00 -- Super new Moon\n",
      "[GlobalWindow] 2021-12-18 15:35:00 -- Micro full moon\n",
      "[GlobalWindow] 2021-12-21 14:59:00 -- December Solstice 2021\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam \n",
    "\n",
    "with beam.Pipeline() as pipeline:\n",
    "    (\n",
    "        pipeline\n",
    "        | \"Astronomical Events\" >> AstronomicalEvents()\n",
    "        | 'Print element info' >> beam.ParDo(PrintElementInfo())\n",
    "        | 'Print window info' >> PrintWindowInfo()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window size : 7776000.0 seconds\n",
      "[2021-01-03 00:00:00 - 2021-04-03 00:00:00] 2021-03-20 07:37:00 -- March Equinox 2021\n",
      "[2021-04-03 00:00:00 - 2021-07-02 00:00:00] 2021-04-27 02:31:00 -- Super Full Moon\n",
      "[2021-04-03 00:00:00 - 2021-07-02 00:00:00] 2021-05-11 17:59:00 -- Micro new Moon\n",
      "[2021-04-03 00:00:00 - 2021-07-02 00:00:00] 2021-05-26 10:13:00 -- Super Full Moon, total lunar eclipse\n",
      "[2021-04-03 00:00:00 - 2021-07-02 00:00:00] 2021-06-21 02:32:00 -- June Solstice 2021\n",
      "[2021-07-02 00:00:00 - 2021-09-30 00:00:00] 2021-08-22 11:01:00 -- September Equinox 2021\n",
      "[2021-07-02 00:00:00 - 2021-09-30 00:00:00] 2021-09-22 18:21:00 -- Super new moon\n",
      "[2021-09-30 00:00:00 - 2021-12-29 00:00:00] 2021-11-19 07:57:00 -- Micro full moon, partial lunar eclipse\n",
      "[2021-09-30 00:00:00 - 2021-12-29 00:00:00] 2021-12-04 06:43:00 -- Super new Moon\n",
      "[2021-09-30 00:00:00 - 2021-12-29 00:00:00] 2021-12-18 15:35:00 -- Micro full moon\n",
      "[2021-09-30 00:00:00 - 2021-12-29 00:00:00] 2021-12-21 14:59:00 -- December Solstice 2021\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam \n",
    "from datetime import timedelta\n",
    "\n",
    "window_size = timedelta(days=3*30).total_seconds()\n",
    "print(f\"window size : {window_size} seconds\")\n",
    "\n",
    "with beam.Pipeline() as pipeline:\n",
    "    (\n",
    "        pipeline\n",
    "        | \"Astronomical Events\" >> AstronomicalEvents()\n",
    "        | 'Fixed window' >> beam.WindowInto(beam.window.FixedWindows(window_size))\n",
    "        | 'Print element info' >> beam.ParDo(PrintElementInfo())\n",
    "        | 'Print window info' >> PrintWindowInfo()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding time windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window size : 7776000.0 seconds\n",
      "window period : 2592000.0 seconds\n",
      "[2021-03-04 00:00:00 - 2021-06-02 00:00:00] 2021-03-20 07:37:00 -- March Equinox 2021\n",
      "[2021-02-02 00:00:00 - 2021-05-03 00:00:00] 2021-03-20 07:37:00 -- March Equinox 2021\n",
      "[2021-01-03 00:00:00 - 2021-04-03 00:00:00] 2021-03-20 07:37:00 -- March Equinox 2021\n",
      "[2021-04-03 00:00:00 - 2021-07-02 00:00:00] 2021-04-27 02:31:00 -- Super Full Moon\n",
      "[2021-03-04 00:00:00 - 2021-06-02 00:00:00] 2021-04-27 02:31:00 -- Super Full Moon\n",
      "[2021-02-02 00:00:00 - 2021-05-03 00:00:00] 2021-04-27 02:31:00 -- Super Full Moon\n",
      "[2021-05-03 00:00:00 - 2021-08-01 00:00:00] 2021-05-11 17:59:00 -- Micro new Moon\n",
      "[2021-04-03 00:00:00 - 2021-07-02 00:00:00] 2021-05-11 17:59:00 -- Micro new Moon\n",
      "[2021-03-04 00:00:00 - 2021-06-02 00:00:00] 2021-05-11 17:59:00 -- Micro new Moon\n",
      "[2021-05-03 00:00:00 - 2021-08-01 00:00:00] 2021-05-26 10:13:00 -- Super Full Moon, total lunar eclipse\n",
      "[2021-04-03 00:00:00 - 2021-07-02 00:00:00] 2021-05-26 10:13:00 -- Super Full Moon, total lunar eclipse\n",
      "[2021-03-04 00:00:00 - 2021-06-02 00:00:00] 2021-05-26 10:13:00 -- Super Full Moon, total lunar eclipse\n",
      "[2021-06-02 00:00:00 - 2021-08-31 00:00:00] 2021-06-21 02:32:00 -- June Solstice 2021\n",
      "[2021-05-03 00:00:00 - 2021-08-01 00:00:00] 2021-06-21 02:32:00 -- June Solstice 2021\n",
      "[2021-04-03 00:00:00 - 2021-07-02 00:00:00] 2021-06-21 02:32:00 -- June Solstice 2021\n",
      "[2021-08-01 00:00:00 - 2021-10-30 00:00:00] 2021-08-22 11:01:00 -- September Equinox 2021\n",
      "[2021-07-02 00:00:00 - 2021-09-30 00:00:00] 2021-08-22 11:01:00 -- September Equinox 2021\n",
      "[2021-06-02 00:00:00 - 2021-08-31 00:00:00] 2021-08-22 11:01:00 -- September Equinox 2021\n",
      "[2021-08-31 00:00:00 - 2021-11-29 00:00:00] 2021-09-22 18:21:00 -- Super new moon\n",
      "[2021-08-01 00:00:00 - 2021-10-30 00:00:00] 2021-09-22 18:21:00 -- Super new moon\n",
      "[2021-07-02 00:00:00 - 2021-09-30 00:00:00] 2021-09-22 18:21:00 -- Super new moon\n",
      "[2021-10-30 00:00:00 - 2022-01-28 00:00:00] 2021-11-19 07:57:00 -- Micro full moon, partial lunar eclipse\n",
      "[2021-09-30 00:00:00 - 2021-12-29 00:00:00] 2021-11-19 07:57:00 -- Micro full moon, partial lunar eclipse\n",
      "[2021-08-31 00:00:00 - 2021-11-29 00:00:00] 2021-11-19 07:57:00 -- Micro full moon, partial lunar eclipse\n",
      "[2021-11-29 00:00:00 - 2022-02-27 00:00:00] 2021-12-04 06:43:00 -- Super new Moon\n",
      "[2021-10-30 00:00:00 - 2022-01-28 00:00:00] 2021-12-04 06:43:00 -- Super new Moon\n",
      "[2021-09-30 00:00:00 - 2021-12-29 00:00:00] 2021-12-04 06:43:00 -- Super new Moon\n",
      "[2021-11-29 00:00:00 - 2022-02-27 00:00:00] 2021-12-18 15:35:00 -- Micro full moon\n",
      "[2021-10-30 00:00:00 - 2022-01-28 00:00:00] 2021-12-18 15:35:00 -- Micro full moon\n",
      "[2021-09-30 00:00:00 - 2021-12-29 00:00:00] 2021-12-18 15:35:00 -- Micro full moon\n",
      "[2021-11-29 00:00:00 - 2022-02-27 00:00:00] 2021-12-21 14:59:00 -- December Solstice 2021\n",
      "[2021-10-30 00:00:00 - 2022-01-28 00:00:00] 2021-12-21 14:59:00 -- December Solstice 2021\n",
      "[2021-09-30 00:00:00 - 2021-12-29 00:00:00] 2021-12-21 14:59:00 -- December Solstice 2021\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam \n",
    "from datetime import timedelta\n",
    "\n",
    "window_size = timedelta(days=3*30).total_seconds()\n",
    "window_period = timedelta(days=30).total_seconds()\n",
    "print(f\"window size : {window_size} seconds\")\n",
    "print(f\"window period : {window_period} seconds\")\n",
    "\n",
    "with beam.Pipeline() as pipeline:\n",
    "    (\n",
    "        pipeline\n",
    "        | \"Astronomical Events\" >> AstronomicalEvents()\n",
    "        | 'Sliding window' >> beam.WindowInto(beam.window.SlidingWindows(window_size, window_period))\n",
    "        | 'Print element info' >> beam.ParDo(PrintElementInfo())\n",
    "        | 'Print window info' >> PrintWindowInfo()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window size : 7776000.0 seconds\n",
      "window period : 2592000.0 seconds\n",
      "[GlobalWindow] 2021-03-20 07:37:00 -- March Equinox 2021\n",
      "[GlobalWindow] 2021-04-27 02:31:00 -- Super Full Moon\n",
      "[GlobalWindow] 2021-05-11 17:59:00 -- Micro new Moon\n",
      "[GlobalWindow] 2021-05-26 10:13:00 -- Super Full Moon, total lunar eclipse\n",
      "[GlobalWindow] 2021-06-21 02:32:00 -- June Solstice 2021\n",
      "[GlobalWindow] 2021-08-22 11:01:00 -- September Equinox 2021\n",
      "[GlobalWindow] 2021-09-22 18:21:00 -- Super new moon\n",
      "[GlobalWindow] 2021-11-19 07:57:00 -- Micro full moon, partial lunar eclipse\n",
      "[GlobalWindow] 2021-12-04 06:43:00 -- Super new Moon\n",
      "[GlobalWindow] 2021-12-18 15:35:00 -- Micro full moon\n",
      "[GlobalWindow] 2021-12-21 14:59:00 -- December Solstice 2021\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam \n",
    "from datetime import timedelta\n",
    "\n",
    "window_size = timedelta(days=3*30).total_seconds()\n",
    "window_period = timedelta(days=30).total_seconds()\n",
    "print(f\"window size : {window_size} seconds\")\n",
    "print(f\"window period : {window_period} seconds\")\n",
    "\n",
    "with beam.Pipeline() as pipeline:\n",
    "    (\n",
    "        pipeline\n",
    "        | \"Astronomical Events\" >> AstronomicalEvents()\n",
    "        | 'Print element info' >> beam.ParDo(PrintElementInfo())\n",
    "        | 'Sliding window' >> beam.WindowInto(beam.window.SlidingWindows(window_size, window_period))  \n",
    "        | 'Print window info' >> PrintWindowInfo()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window size : 2592000.0 seconds\n",
      "[2021-03-20 07:37:00 - 2021-04-19 07:37:00] 2021-03-20 07:37:00 -- March Equinox 2021\n",
      "[2021-04-27 02:31:00 - 2021-05-27 02:31:00] 2021-04-27 02:31:00 -- Super Full Moon\n",
      "[2021-05-11 17:59:00 - 2021-06-10 17:59:00] 2021-05-11 17:59:00 -- Micro new Moon\n",
      "[2021-05-26 10:13:00 - 2021-06-25 10:13:00] 2021-05-26 10:13:00 -- Super Full Moon, total lunar eclipse\n",
      "[2021-06-21 02:32:00 - 2021-07-21 02:32:00] 2021-06-21 02:32:00 -- June Solstice 2021\n",
      "[2021-08-22 11:01:00 - 2021-09-21 11:01:00] 2021-08-22 11:01:00 -- September Equinox 2021\n",
      "[2021-09-22 18:21:00 - 2021-10-22 18:21:00] 2021-09-22 18:21:00 -- Super new moon\n",
      "[2021-11-19 07:57:00 - 2021-12-19 07:57:00] 2021-11-19 07:57:00 -- Micro full moon, partial lunar eclipse\n",
      "[2021-12-04 06:43:00 - 2022-01-03 06:43:00] 2021-12-04 06:43:00 -- Super new Moon\n",
      "[2021-12-18 15:35:00 - 2022-01-17 15:35:00] 2021-12-18 15:35:00 -- Micro full moon\n",
      "[2021-12-21 14:59:00 - 2022-01-20 14:59:00] 2021-12-21 14:59:00 -- December Solstice 2021\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam \n",
    "from datetime import timedelta\n",
    "\n",
    "gap_size = timedelta(days=30).total_seconds()\n",
    "print(f\"window size : {gap_size} seconds\")\n",
    "\n",
    "with beam.Pipeline() as pipeline:\n",
    "    (\n",
    "        pipeline\n",
    "        | \"Astronomical Events\" >> AstronomicalEvents()\n",
    "        | 'Sliding window' >> beam.WindowInto(beam.window.Sessions(gap_size))\n",
    "        | 'Print element info' >> beam.ParDo(PrintElementInfo())\n",
    "        | 'Print window info' >> PrintWindowInfo()\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
