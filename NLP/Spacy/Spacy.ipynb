{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install spacy\n",
    "# python -m spacy download en_core_web_sm\n",
    "# python -m spacy download en_core_web_md\n",
    "# python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing modules and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "text = \"\"\"Queen Elizabeth II made personal additions to plans for her funeral day, Buckingham Palace has said.\n",
    "Among the touches requested by the Queen is the playing of a lament by her piper.\n",
    "The state funeral at Westminster Abbey on Monday is likely to be one of the biggest single ceremonial events staged in Britain since World War Two.\"\"\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization & Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Queen', 'Elizabeth', 'II', 'made', 'personal', 'additions', 'to', 'plans', 'for', 'her', 'funeral', 'day', ',', 'Buckingham', 'Palace', 'has', 'said', '.', '\\n', 'Among', 'the', 'touches', 'requested', 'by', 'the', 'Queen', 'is', 'the', 'playing', 'of', 'a', 'lament', 'by', 'her', 'piper', '.', '\\n', 'The', 'state', 'funeral', 'at', 'Westminster', 'Abbey', 'on', 'Monday', 'is', 'likely', 'to', 'be', 'one', 'of', 'the', 'biggest', 'single', 'ceremonial', 'events', 'staged', 'in', 'Britain', 'since', 'World', 'War', 'Two', '.']\n",
      "64\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "print([token.text for token in doc])\n",
    "print(len(doc))\n",
    "print(len([token.text for token in doc]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    pass\n",
    "\n",
    "print(type(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queen Elizabeth II made personal <class 'spacy.tokens.span.Span'>\n"
     ]
    }
   ],
   "source": [
    "span = doc[:5]\n",
    "print(span.text, type(span))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Queen', 'Elizabeth', 'II', 'made', 'personal', 'additions', 'to', 'plans', 'for', 'her', 'funeral', 'day', ',', 'Buckingham', 'Palace', 'has', 'said', '.', '\\n', 'Among', 'the', 'touches', 'requested', 'by', 'the', 'Queen', 'is', 'the', 'playing', 'of', 'a', 'lament', 'by', 'her', 'piper', '.', '\\n', 'The', 'state', 'funeral', 'at', 'Westminster', 'Abbey', 'on', 'Monday', 'is', 'likely', 'to', 'be', 'one', 'of', 'the', 'biggest', 'single', 'ceremonial', 'events', 'staged', 'in', 'Britain', 'since', 'World', 'War', 'Two', '.']\n"
     ]
    }
   ],
   "source": [
    "news_text = open('news.txt').read()\n",
    "news_doc = nlp(news_text)\n",
    "print([token.text for token in news_doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Communication in Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5479190301435931735"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp.vocab.strings)\n",
    "spacy.strings.StringStore\n",
    "nlp.vocab.strings[\"Elizabeth\"]  # Hash code of the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Elizabeth'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.strings[5479190301435931735]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Queen Elizabeth II made personal additions to plans for her funeral day, Buckingham Palace has said.\n",
      "\n",
      "Among the touches requested by the Queen is the playing of a lament by her piper.\n",
      "\n",
      "The state funeral at Westminster Abbey on Monday is likely to be one of the biggest single ceremonial events staged in Britain since World War Two.\n"
     ]
    }
   ],
   "source": [
    "sentences = list(doc.sents)\n",
    "print(len(sentences))\n",
    "for s in sentences:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I went to visit the Niagara waterfalls last weekend.\n",
      "It was a magnificient show of nature at its glory.\n",
      "The horse shoe falls moves south to east and has several whirls along its rocky terrain.\n",
      "The white water walk was the highest part of this once in a lifetime tour...I would definitely want to come back again\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"I went to visit the Niagara waterfalls last weekend. It was a magnificient show of nature at its glory. The horse shoe falls moves south to east and has several whirls along its rocky terrain. The white water walk was the highest part of this once in a lifetime tour...I would definitely want to come back again\"\"\"\n",
    "doc = nlp(text)\n",
    "for s in list(doc.sents):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.set_custom_boundaries(doc)>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.language import Language\n",
    "\n",
    "@Language.component(\"component\")\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == \"...\":\n",
    "            doc[token.i+1].is_sent_start = True \n",
    "    return doc\n",
    "\n",
    "st_nlp = spacy.load('en_core_web_sm')\n",
    "st_nlp.add_pipe(\"component\", before=\"parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'went', 'to', 'visit', 'the', 'Niagara', 'waterfalls', 'last', 'weekend', '.', 'It', 'was', 'a', 'magnificient', 'show', 'of', 'nature', 'at', 'its', 'glory', '.', 'The', 'horse', 'shoe', 'falls', 'moves', 'south', 'to', 'east', 'and', 'has', 'several', 'whirls', 'along', 'its', 'rocky', 'terrain', '.', 'The', 'white', 'water', 'walk', 'was', 'the', 'highest', 'part', 'of', 'this', 'once', 'in', 'a', 'lifetime', 'tour', '...', 'I', 'would', 'definitely', 'want', 'to', 'come', 'back', 'again']\n",
      "I went to visit the Niagara waterfalls last weekend.\n",
      "It was a magnificient show of nature at its glory.\n",
      "The horse shoe falls moves south to east and has several whirls along its rocky terrain.\n",
      "The white water walk was the highest part of this once in a lifetime tour...\n",
      "I would definitely want to come back again\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"I went to visit the Niagara waterfalls last weekend. It was a magnificient show of nature at its glory. The horse shoe falls moves south to east and has several whirls along its rocky terrain. The white water walk was the highest part of this once in a lifetime tour...I would definitely want to come back again\"\"\"\n",
    "doc = st_nlp(text)\n",
    "print([token.text for token in doc])\n",
    "\n",
    "for s in list(doc.sents):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization Details\n",
    "* text_with_ws : Prints token with trailing space\n",
    "* is_alpha : Consists of alphabetic characters or not\n",
    "* is_space : Detects a space\n",
    "* is_punct : Punctutaion symbol or not\n",
    "* shape_ : Shape of the word. Also distinguishes numerals and punctutaions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queen           0    Queen                       1      0      0      Xxxxx                False\n",
      "Elizabeth       6    Elizabeth                   1      0      0      Xxxxx                False\n",
      "II              16   II                          1      0      0      XX                   False\n",
      "(               19   (                           0      1      0      (                    False\n",
      "1926            20   1926                        0      0      0      dddd                 False\n",
      "-               25   -                           0      1      0      -                    False\n",
      "2022            27   2022                        0      0      0      dddd                 False\n",
      ")               31   )                           0      1      0      )                    False\n",
      "made            33   made                        1      0      0      xxxx                 True\n",
      "personal        38   personal                    1      0      0      xxxx                 False\n",
      "additions       47   additions                   1      0      0      xxxx                 False\n",
      "to              57   to                          1      0      0      xx                   True\n",
      "plans           60   plans                       1      0      0      xxxx                 False\n",
      "for             66   for                         1      0      0      xxx                  True\n",
      "her             70   her                         1      0      0      xxx                  True\n",
      "funeral         74   funeral                     1      0      0      xxxx                 False\n",
      "day             82   day                         1      0      0      xxx                  False\n",
      ",               85   ,                           0      1      0      ,                    False\n",
      "Buckingham      87   Buckingham                  1      0      0      Xxxxx                False\n",
      "Palace          98   Palace                      1      0      0      Xxxxx                False\n",
      "has             105  has                         1      0      0      xxx                  True\n",
      "said            109  said                        1      0      0      xxxx                 False\n",
      ".               113  .                           0      1      0      .                    False\n",
      "\n",
      "               114  \n",
      "                           0      0      1      \n",
      "                    False\n",
      "Among           115  Among                       1      0      0      Xxxxx                True\n",
      "the             121  the                         1      0      0      xxx                  True\n",
      "touches         125  touches                     1      0      0      xxxx                 False\n",
      "requested       133  requested                   1      0      0      xxxx                 False\n",
      "by              143  by                          1      0      0      xx                   True\n",
      "the             146  the                         1      0      0      xxx                  True\n",
      "Queen           150  Queen                       1      0      0      Xxxxx                False\n",
      "is              156  is                          1      0      0      xx                   True\n",
      "the             159  the                         1      0      0      xxx                  True\n",
      "playing         163  playing                     1      0      0      xxxx                 False\n",
      "of              171  of                          1      0      0      xx                   True\n",
      "a               174  a                           1      0      0      x                    True\n",
      "lament          176  lament                      1      0      0      xxxx                 False\n",
      "by              183  by                          1      0      0      xx                   True\n",
      "her             186  her                         1      0      0      xxx                  True\n",
      "piper           190  piper                       1      0      0      xxxx                 False\n",
      ".               195  .                           0      1      0      .                    False\n",
      "\n",
      "               196  \n",
      "                           0      0      1      \n",
      "                    False\n",
      "The             197  The                         1      0      0      Xxx                  True\n",
      "state           201  state                       1      0      0      xxxx                 False\n",
      "funeral         207  funeral                     1      0      0      xxxx                 False\n",
      "at              215  at                          1      0      0      xx                   True\n",
      "Westminster     218  Westminster                 1      0      0      Xxxxx                False\n",
      "Abbey           230  Abbey                       1      0      0      Xxxxx                False\n",
      "on              236  on                          1      0      0      xx                   True\n",
      "Monday          239  Monday                      1      0      0      Xxxxx                False\n",
      "is              246  is                          1      0      0      xx                   True\n",
      "likely          249  likely                      1      0      0      xxxx                 False\n",
      "to              256  to                          1      0      0      xx                   True\n",
      "be              259  be                          1      0      0      xx                   True\n",
      "one             262  one                         1      0      0      xxx                  True\n",
      "of              266  of                          1      0      0      xx                   True\n",
      "the             269  the                         1      0      0      xxx                  True\n",
      "biggest         273  biggest                     1      0      0      xxxx                 False\n",
      "single          281  single                      1      0      0      xxxx                 False\n",
      "ceremonial      288  ceremonial                  1      0      0      xxxx                 False\n",
      "events          299  events                      1      0      0      xxxx                 False\n",
      "staged          306  staged                      1      0      0      xxxx                 False\n",
      "in              313  in                          1      0      0      xx                   True\n",
      "Britain         316  Britain                     1      0      0      Xxxxx                False\n",
      "since           324  since                       1      0      0      xxxx                 True\n",
      "World           330  World                       1      0      0      Xxxxx                False\n",
      "War             336  War                         1      0      0      Xxx                  False\n",
      "Two             340  Two                         1      0      0      Xxx                  True\n",
      ".               343  .                           0      1      0      .                    False\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "text = \"\"\"Queen Elizabeth II (1926 - 2022) made personal additions to plans for her funeral day, Buckingham Palace has said.\n",
    "Among the touches requested by the Queen is the playing of a lament by her piper.\n",
    "The state funeral at Westminster Abbey on Monday is likely to be one of the biggest single ceremonial events staged in Britain since World War Two.\"\"\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<15} {token.idx:<4} {token.text_with_ws:<20}\\\n",
    "        {token.is_alpha:<6} {token.is_punct:<6} {token.is_space:<6} {token.shape_:<20} {token.is_stop}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index :         [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Text :          ['Queen', 'Elizabeth', 'II', '(', '1926', '-', '2022', ')', 'made', 'personal']\n",
      "is_alpha :      [True, True, True, False, False, False, False, False, True, True]\n",
      "like_num :      [False, False, False, False, True, False, True, False, False, False]\n",
      "Base word :     ['Queen', 'Elizabeth', 'II', '(', '1926', '-', '2022', ')', 'make', 'personal']\n"
     ]
    }
   ],
   "source": [
    "print(\"Index :        \", [token.i for token in doc[:10]])\n",
    "print(\"Text :         \", [token.text for token in doc[:10]])\n",
    "print(\"is_alpha :     \", [token.is_alpha for token in doc[:10]])\n",
    "print(\"like_num :     \", [token.like_num for token in doc[:10]])\n",
    "print(\"Base word :    \", [token.lemma_ for token in doc[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['top',\n",
       " 'his',\n",
       " 'fifteen',\n",
       " 'what',\n",
       " 'onto',\n",
       " 'although',\n",
       " 'three',\n",
       " 'however',\n",
       " 'over',\n",
       " 'or',\n",
       " 'namely',\n",
       " 'how',\n",
       " 'hereupon',\n",
       " 'do',\n",
       " 'whose',\n",
       " 'our',\n",
       " 'be',\n",
       " 'full',\n",
       " 'fifty',\n",
       " 'until']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy \n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "print(len(spacy_stopwords))\n",
    "\n",
    "list(spacy_stopwords)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[made, to, for, her, has, Among, the, by, the, is, the, of, a, by, her, The, at, on, is, to, be, one, of, the, in, since, Two, A, two, will, be, as, the, to, a, just, before, The, of, with, its, of, and, is, to, more, of, the, 's, for, the, say, the, had, been, on, all, the, Among, those, to, their, at, the, which, at, are, US, and, and, will, be, who, were, in, the, 's, those, who, with, the, to, the, A, former, the, after, being, is, among, those, due, to, the, I, 'm, to, be, The, of, 's, the, the, of, his, was, both, and]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "text = \"\"\"Queen Elizabeth II made personal additions to plans for her funeral day, Buckingham Palace has said.\n",
    "Among the touches requested by the Queen is the playing of a lament by her piper.\n",
    "The state funeral at Westminster Abbey on Monday is likely to be one of the biggest single ceremonial events staged in Britain since World War Two.\n",
    "A national two-minute silence will be held as the service draws to a close just before midday.\n",
    "The order of service, with its choice of music and readings, is expected to reflect more of the Queen's personal choices for the funeral.\n",
    "Palace aides say the Queen had been consulted on all the arrangements.\n",
    "Among those to confirm their attendance at the state funeral, which starts at 11:00 BST, are US President Joe Biden and French President Emmanuel Macron.\n",
    "Alongside royalty, politicians and world leaders will be 200 people who were recognised in the Queen's Birthday Honours, including those who helped with the response to the coronavirus pandemic.\n",
    "A former police officer awarded the George Cross after being shot 15 times is among those due to attend the state funeral.\n",
    "Tony Gledhill, 84, said: \"I'm incredibly moved to be involved.\"\n",
    "The official organiser of Monday's events, the Earl Marshal, the Duke of Norfolk, said his role was \"both humbling and daunting\".\"\"\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "# tokens_wo_sw = []\n",
    "# for token in doc:\n",
    "#     if not token.is_stop:\n",
    "#         tokens_wo_sw.append(token)\n",
    "# #print(tokens_wo_sw)\n",
    "\n",
    "print([token for token in doc if  token.is_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "Reduced form or root word is called lemma.\n",
    "Changes tense, number, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queen                 Queen               \n",
      "Elizabeth             Elizabeth           \n",
      "II                    II                  \n",
      "made                  make                \n",
      "personal              personal            \n",
      "additions             addition            \n",
      "to                    to                  \n",
      "plans                 plan                \n",
      "for                   for                 \n",
      "her                   her                 \n",
      "funeral               funeral             \n",
      "day                   day                 \n",
      ",                     ,                   \n",
      "Buckingham            Buckingham          \n",
      "Palace                Palace              \n",
      "has                   have                \n",
      "said                  say                 \n",
      ".                     .                   \n",
      "\n",
      "                     \n",
      "                   \n",
      "Among                 among               \n",
      "the                   the                 \n",
      "touches               touch               \n",
      "requested             request             \n",
      "by                    by                  \n",
      "the                   the                 \n",
      "Queen                 Queen               \n",
      "is                    be                  \n",
      "the                   the                 \n",
      "playing               playing             \n",
      "of                    of                  \n",
      "a                     a                   \n",
      "lament                lament              \n",
      "by                    by                  \n",
      "her                   her                 \n",
      "piper                 piper               \n",
      ".                     .                   \n",
      "\n",
      "                     \n",
      "                   \n",
      "The                   the                 \n",
      "state                 state               \n",
      "funeral               funeral             \n",
      "at                    at                  \n",
      "Westminster           Westminster         \n",
      "Abbey                 Abbey               \n",
      "on                    on                  \n",
      "Monday                Monday              \n",
      "is                    be                  \n",
      "likely                likely              \n",
      "to                    to                  \n",
      "be                    be                  \n",
      "one                   one                 \n",
      "of                    of                  \n",
      "the                   the                 \n",
      "biggest               big                 \n",
      "single                single              \n",
      "ceremonial            ceremonial          \n",
      "events                event               \n",
      "staged                stage               \n",
      "in                    in                  \n",
      "Britain               Britain             \n",
      "since                 since               \n",
      "World                 World               \n",
      "War                   War                 \n",
      "Two                   two                 \n",
      ".                     .                   \n",
      "\n",
      "                     \n",
      "                   \n",
      "A                     a                   \n",
      "national              national            \n",
      "two                   two                 \n",
      "-                     -                   \n",
      "minute                minute              \n",
      "silence               silence             \n",
      "will                  will                \n",
      "be                    be                  \n",
      "held                  hold                \n",
      "as                    as                  \n",
      "the                   the                 \n",
      "service               service             \n",
      "draws                 draw                \n",
      "to                    to                  \n",
      "a                     a                   \n",
      "close                 close               \n",
      "just                  just                \n",
      "before                before              \n",
      "midday                midday              \n",
      ".                     .                   \n",
      "\n",
      "                     \n",
      "                   \n",
      "The                   the                 \n",
      "order                 order               \n",
      "of                    of                  \n",
      "service               service             \n",
      ",                     ,                   \n",
      "with                  with                \n",
      "its                   its                 \n",
      "choice                choice              \n",
      "of                    of                  \n",
      "music                 music               \n",
      "and                   and                 \n",
      "readings              reading             \n",
      ",                     ,                   \n",
      "is                    be                  \n",
      "expected              expect              \n",
      "to                    to                  \n",
      "reflect               reflect             \n",
      "more                  more                \n",
      "of                    of                  \n",
      "the                   the                 \n",
      "Queen                 Queen               \n",
      "'s                    's                  \n",
      "personal              personal            \n",
      "choices               choice              \n",
      "for                   for                 \n",
      "the                   the                 \n",
      "funeral               funeral             \n",
      ".                     .                   \n",
      "\n",
      "                     \n",
      "                   \n",
      "Palace                Palace              \n",
      "aides                 aide                \n",
      "say                   say                 \n",
      "the                   the                 \n",
      "Queen                 Queen               \n",
      "had                   have                \n",
      "been                  be                  \n",
      "consulted             consult             \n",
      "on                    on                  \n",
      "all                   all                 \n",
      "the                   the                 \n",
      "arrangements          arrangement         \n",
      ".                     .                   \n",
      "\n",
      "                     \n",
      "                   \n",
      "Among                 among               \n",
      "those                 those               \n",
      "to                    to                  \n",
      "confirm               confirm             \n",
      "their                 their               \n",
      "attendance            attendance          \n",
      "at                    at                  \n",
      "the                   the                 \n",
      "state                 state               \n",
      "funeral               funeral             \n",
      ",                     ,                   \n",
      "which                 which               \n",
      "starts                start               \n",
      "at                    at                  \n",
      "11:00                 11:00               \n",
      "BST                   BST                 \n",
      ",                     ,                   \n",
      "are                   be                  \n",
      "US                    US                  \n",
      "President             President           \n",
      "Joe                   Joe                 \n",
      "Biden                 Biden               \n",
      "and                   and                 \n",
      "French                french              \n",
      "President             President           \n",
      "Emmanuel              Emmanuel            \n",
      "Macron                Macron              \n",
      ".                     .                   \n",
      "\n",
      "                     \n",
      "                   \n",
      "Alongside             alongside           \n",
      "royalty               royalty             \n",
      ",                     ,                   \n",
      "politicians           politician          \n",
      "and                   and                 \n",
      "world                 world               \n",
      "leaders               leader              \n",
      "will                  will                \n",
      "be                    be                  \n",
      "200                   200                 \n",
      "people                people              \n",
      "who                   who                 \n",
      "were                  be                  \n",
      "recognised            recognise           \n",
      "in                    in                  \n",
      "the                   the                 \n",
      "Queen                 Queen               \n",
      "'s                    's                  \n",
      "Birthday              Birthday            \n",
      "Honours               Honours             \n",
      ",                     ,                   \n",
      "including             include             \n",
      "those                 those               \n",
      "who                   who                 \n",
      "helped                help                \n",
      "with                  with                \n",
      "the                   the                 \n",
      "response              response            \n",
      "to                    to                  \n",
      "the                   the                 \n",
      "coronavirus           coronavirus         \n",
      "pandemic              pandemic            \n",
      ".                     .                   \n",
      "\n",
      "                     \n",
      "                   \n",
      "A                     a                   \n",
      "former                former              \n",
      "police                police              \n",
      "officer               officer             \n",
      "awarded               award               \n",
      "the                   the                 \n",
      "George                George              \n",
      "Cross                 Cross               \n",
      "after                 after               \n",
      "being                 be                  \n",
      "shot                  shoot               \n",
      "15                    15                  \n",
      "times                 time                \n",
      "is                    be                  \n",
      "among                 among               \n",
      "those                 those               \n",
      "due                   due                 \n",
      "to                    to                  \n",
      "attend                attend              \n",
      "the                   the                 \n",
      "state                 state               \n",
      "funeral               funeral             \n",
      ".                     .                   \n",
      "\n",
      "                     \n",
      "                   \n",
      "Tony                  Tony                \n",
      "Gledhill              Gledhill            \n",
      ",                     ,                   \n",
      "84                    84                  \n",
      ",                     ,                   \n",
      "said                  say                 \n",
      ":                     :                   \n",
      "\"                     \"                   \n",
      "I                     I                   \n",
      "'m                    be                  \n",
      "incredibly            incredibly          \n",
      "moved                 move                \n",
      "to                    to                  \n",
      "be                    be                  \n",
      "involved              involve             \n",
      ".                     .                   \n",
      "\"                     \"                   \n",
      "\n",
      "                     \n",
      "                   \n",
      "The                   the                 \n",
      "official              official            \n",
      "organiser             organiser           \n",
      "of                    of                  \n",
      "Monday                Monday              \n",
      "'s                    's                  \n",
      "events                event               \n",
      ",                     ,                   \n",
      "the                   the                 \n",
      "Earl                  Earl                \n",
      "Marshal               Marshal             \n",
      ",                     ,                   \n",
      "the                   the                 \n",
      "Duke                  Duke                \n",
      "of                    of                  \n",
      "Norfolk               Norfolk             \n",
      ",                     ,                   \n",
      "said                  say                 \n",
      "his                   his                 \n",
      "role                  role                \n",
      "was                   be                  \n",
      "\"                     \"                   \n",
      "both                  both                \n",
      "humbling              humble              \n",
      "and                   and                 \n",
      "daunting              daunt               \n",
      "\"                     \"                   \n",
      ".                     .                   \n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f\"{token.text:<20}  {token.lemma_:<20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Queen', 5), ('funeral', 5), ('said', 3), ('state', 3), ('personal', 2), ('Palace', 2), ('Monday', 2), ('events', 2), ('service', 2), ('President', 2)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter \n",
    "\n",
    "words = [token.text for token in doc if not token.is_stop and not token.is_punct and not token.text == '\\n']\n",
    "\n",
    "word_freq = Counter(words)\n",
    "\n",
    "common_words = word_freq.most_common(10)\n",
    "print(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'piper', 'Emmanuel', 'Elizabeth', 'awarded', 'role', 'starts', 'Buckingham', '11:00', 'including', 'Palace', 'choices', 'touches', 'biggest', 'Birthday', '200', 'reflect', 'Earl', 'requested', 'response', 'organiser', 'Gledhill', 'leaders', 'silence', 'held', 'Norfolk', 'Macron', 'police', 'times', 'service', 'events', 'official', 'consulted', 'additions', '84', 'attend', 'single', 'Alongside', 'royalty', 'Honours', 'draws', 'readings', 'BST', 'moved', 'ceremonial', 'officer', 'War', 'day', 'Westminster', 'plans', 'said', 'choice', 'aides', 'minute', 'Britain', 'pandemic', 'World', 'Tony', 'shot', 'French', 'lament', 'arrangements', 'confirm', 'politicians', 'expected', 'Cross', 'George', 'playing', 'state', 'attendance', 'people', 'Biden', 'personal', 'helped', 'humbling', 'order', 'daunting', 'staged', 'President', '15', 'music', 'close', 'likely', 'Marshal', 'incredibly', 'Duke', 'midday', 'II', 'Joe', 'coronavirus', 'funeral', 'national', 'world', 'involved', 'Monday', 'Abbey', 'Queen', 'recognised'}\n"
     ]
    }
   ],
   "source": [
    "# Unique words\n",
    "unique_words = {word for (word, freq) in word_freq.items() }\n",
    "print(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 17), (',', 12), ('.', 11), ('\\n', 10), ('to', 8), ('of', 7), ('Queen', 5), ('funeral', 5), ('is', 4), ('be', 4)]\n"
     ]
    }
   ],
   "source": [
    "# Without reviewing stopwords\n",
    "words = [token.text for token in doc ]\n",
    "\n",
    "word_freq = Counter(words)\n",
    "\n",
    "common_words = word_freq.most_common(10)\n",
    "print(common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS Tagging\n",
    "\n",
    "Eight parts of speech:\n",
    "1. Noun\n",
    "2. Pronoun\n",
    "3. verb\n",
    "4. Adjective\n",
    "5. Adverb\n",
    "6. Preposition\n",
    "7. COnjunction\n",
    "8. Interjection\n",
    "\n",
    "* pos_ : Coarse grained POS\n",
    "* tag_ : Fine grained POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queen                PROPN                NNP                  II                   proper noun                              noun, proper singular\n",
      "Elizabeth            PROPN                NNP                  II                   proper noun                              noun, proper singular\n",
      "II                   PROPN                NNP                  made                 proper noun                              noun, proper singular\n",
      "made                 VERB                 VBD                  said                 verb                                     verb, past tense\n",
      "personal             ADJ                  JJ                   additions            adjective                                adjective (English), other noun-modifier (Chinese)\n",
      "additions            NOUN                 NNS                  made                 noun                                     noun, plural\n",
      "to                   ADP                  IN                   made                 adposition                               conjunction, subordinating or preposition\n",
      "plans                NOUN                 NNS                  to                   noun                                     noun, plural\n",
      "for                  ADP                  IN                   plans                adposition                               conjunction, subordinating or preposition\n",
      "her                  PRON                 PRP$                 day                  pronoun                                  pronoun, possessive\n",
      "funeral              ADJ                  JJ                   day                  adjective                                adjective (English), other noun-modifier (Chinese)\n",
      "day                  NOUN                 NN                   for                  noun                                     noun, singular or mass\n",
      ",                    PUNCT                ,                    said                 punctuation                              punctuation mark, comma\n",
      "Buckingham           PROPN                NNP                  Palace               proper noun                              noun, proper singular\n",
      "Palace               PROPN                NNP                  said                 proper noun                              noun, proper singular\n",
      "has                  AUX                  VBZ                  said                 auxiliary                                verb, 3rd person singular present\n",
      "said                 VERB                 VBN                  said                 verb                                     verb, past participle\n",
      ".                    PUNCT                .                    said                 punctuation                              punctuation mark, sentence closer\n",
      "\n",
      "                    SPACE                _SP                  .                    space                                    whitespace\n",
      "Among                ADP                  IN                   is                   adposition                               conjunction, subordinating or preposition\n",
      "the                  DET                  DT                   touches              determiner                               determiner\n",
      "touches              NOUN                 NNS                  Among                noun                                     noun, plural\n",
      "requested            VERB                 VBN                  touches              verb                                     verb, past participle\n",
      "by                   ADP                  IN                   requested            adposition                               conjunction, subordinating or preposition\n",
      "the                  DET                  DT                   Queen                determiner                               determiner\n",
      "Queen                PROPN                NNP                  by                   proper noun                              noun, proper singular\n",
      "is                   AUX                  VBZ                  is                   auxiliary                                verb, 3rd person singular present\n",
      "the                  DET                  DT                   playing              determiner                               determiner\n",
      "playing              NOUN                 NN                   is                   noun                                     noun, singular or mass\n",
      "of                   ADP                  IN                   playing              adposition                               conjunction, subordinating or preposition\n",
      "a                    DET                  DT                   lament               determiner                               determiner\n",
      "lament               NOUN                 NN                   of                   noun                                     noun, singular or mass\n",
      "by                   ADP                  IN                   lament               adposition                               conjunction, subordinating or preposition\n",
      "her                  PRON                 PRP$                 piper                pronoun                                  pronoun, possessive\n",
      "piper                NOUN                 NN                   by                   noun                                     noun, singular or mass\n",
      ".                    PUNCT                .                    is                   punctuation                              punctuation mark, sentence closer\n",
      "\n",
      "                    SPACE                _SP                  .                    space                                    whitespace\n",
      "The                  DET                  DT                   funeral              determiner                               determiner\n",
      "state                NOUN                 NN                   funeral              noun                                     noun, singular or mass\n",
      "funeral              NOUN                 NN                   is                   noun                                     noun, singular or mass\n",
      "at                   ADP                  IN                   funeral              adposition                               conjunction, subordinating or preposition\n",
      "Westminster          PROPN                NNP                  Abbey                proper noun                              noun, proper singular\n",
      "Abbey                PROPN                NNP                  at                   proper noun                              noun, proper singular\n",
      "on                   ADP                  IN                   funeral              adposition                               conjunction, subordinating or preposition\n",
      "Monday               PROPN                NNP                  on                   proper noun                              noun, proper singular\n",
      "is                   AUX                  VBZ                  is                   auxiliary                                verb, 3rd person singular present\n",
      "likely               ADJ                  JJ                   is                   adjective                                adjective (English), other noun-modifier (Chinese)\n",
      "to                   PART                 TO                   be                   particle                                 infinitival \"to\"\n",
      "be                   AUX                  VB                   likely               auxiliary                                verb, base form\n",
      "one                  NUM                  CD                   be                   numeral                                  cardinal number\n",
      "of                   ADP                  IN                   one                  adposition                               conjunction, subordinating or preposition\n",
      "the                  DET                  DT                   events               determiner                               determiner\n",
      "biggest              ADJ                  JJS                  events               adjective                                adjective, superlative\n",
      "single               ADJ                  JJ                   events               adjective                                adjective (English), other noun-modifier (Chinese)\n",
      "ceremonial           ADJ                  JJ                   events               adjective                                adjective (English), other noun-modifier (Chinese)\n",
      "events               NOUN                 NNS                  of                   noun                                     noun, plural\n",
      "staged               VERB                 VBD                  events               verb                                     verb, past tense\n",
      "in                   ADP                  IN                   staged               adposition                               conjunction, subordinating or preposition\n",
      "Britain              PROPN                NNP                  in                   proper noun                              noun, proper singular\n",
      "since                SCONJ                IN                   staged               subordinating conjunction                conjunction, subordinating or preposition\n",
      "World                PROPN                NNP                  War                  proper noun                              noun, proper singular\n",
      "War                  PROPN                NNP                  since                proper noun                              noun, proper singular\n",
      "Two                  NUM                  CD                   War                  numeral                                  cardinal number\n",
      ".                    PUNCT                .                    is                   punctuation                              punctuation mark, sentence closer\n",
      "\n",
      "                    SPACE                _SP                  .                    space                                    whitespace\n",
      "A                    DET                  DT                   silence              determiner                               determiner\n",
      "national             ADJ                  JJ                   silence              adjective                                adjective (English), other noun-modifier (Chinese)\n",
      "two                  NUM                  CD                   minute               numeral                                  cardinal number\n",
      "-                    PUNCT                HYPH                 minute               punctuation                              punctuation mark, hyphen\n",
      "minute               NOUN                 NN                   silence              noun                                     noun, singular or mass\n",
      "silence              NOUN                 NN                   held                 noun                                     noun, singular or mass\n",
      "will                 AUX                  MD                   held                 auxiliary                                verb, modal auxiliary\n",
      "be                   AUX                  VB                   held                 auxiliary                                verb, base form\n",
      "held                 VERB                 VBN                  held                 verb                                     verb, past participle\n",
      "as                   SCONJ                IN                   draws                subordinating conjunction                conjunction, subordinating or preposition\n",
      "the                  DET                  DT                   service              determiner                               determiner\n",
      "service              NOUN                 NN                   draws                noun                                     noun, singular or mass\n",
      "draws                VERB                 VBZ                  held                 verb                                     verb, 3rd person singular present\n",
      "to                   ADP                  IN                   draws                adposition                               conjunction, subordinating or preposition\n",
      "a                    DET                  DT                   close                determiner                               determiner\n",
      "close                NOUN                 NN                   to                   noun                                     noun, singular or mass\n",
      "just                 ADV                  RB                   before               adverb                                   adverb\n",
      "before               ADP                  IN                   draws                adposition                               conjunction, subordinating or preposition\n",
      "midday               NOUN                 NN                   before               noun                                     noun, singular or mass\n",
      ".                    PUNCT                .                    held                 punctuation                              punctuation mark, sentence closer\n",
      "\n",
      "                    SPACE                _SP                  .                    space                                    whitespace\n",
      "The                  DET                  DT                   order                determiner                               determiner\n",
      "order                NOUN                 NN                   expected             noun                                     noun, singular or mass\n",
      "of                   ADP                  IN                   order                adposition                               conjunction, subordinating or preposition\n",
      "service              NOUN                 NN                   of                   noun                                     noun, singular or mass\n",
      ",                    PUNCT                ,                    order                punctuation                              punctuation mark, comma\n",
      "with                 ADP                  IN                   order                adposition                               conjunction, subordinating or preposition\n",
      "its                  PRON                 PRP$                 choice               pronoun                                  pronoun, possessive\n",
      "choice               NOUN                 NN                   with                 noun                                     noun, singular or mass\n",
      "of                   ADP                  IN                   choice               adposition                               conjunction, subordinating or preposition\n",
      "music                NOUN                 NN                   of                   noun                                     noun, singular or mass\n",
      "and                  CCONJ                CC                   music                coordinating conjunction                 conjunction, coordinating\n",
      "readings             NOUN                 NNS                  music                noun                                     noun, plural\n",
      ",                    PUNCT                ,                    order                punctuation                              punctuation mark, comma\n",
      "is                   AUX                  VBZ                  expected             auxiliary                                verb, 3rd person singular present\n",
      "expected             VERB                 VBN                  expected             verb                                     verb, past participle\n",
      "to                   PART                 TO                   reflect              particle                                 infinitival \"to\"\n",
      "reflect              VERB                 VB                   expected             verb                                     verb, base form\n",
      "more                 ADJ                  JJR                  reflect              adjective                                adjective, comparative\n",
      "of                   ADP                  IN                   more                 adposition                               conjunction, subordinating or preposition\n",
      "the                  DET                  DT                   Queen                determiner                               determiner\n",
      "Queen                PROPN                NNP                  choices              proper noun                              noun, proper singular\n",
      "'s                   PART                 POS                  Queen                particle                                 possessive ending\n",
      "personal             ADJ                  JJ                   choices              adjective                                adjective (English), other noun-modifier (Chinese)\n",
      "choices              NOUN                 NNS                  of                   noun                                     noun, plural\n",
      "for                  ADP                  IN                   reflect              adposition                               conjunction, subordinating or preposition\n",
      "the                  DET                  DT                   funeral              determiner                               determiner\n",
      "funeral              NOUN                 NN                   for                  noun                                     noun, singular or mass\n",
      ".                    PUNCT                .                    expected             punctuation                              punctuation mark, sentence closer\n",
      "\n",
      "                    SPACE                _SP                  .                    space                                    whitespace\n",
      "Palace               PROPN                NNP                  aides                proper noun                              noun, proper singular\n",
      "aides                NOUN                 NNS                  say                  noun                                     noun, plural\n",
      "say                  VERB                 VBP                  say                  verb                                     verb, non-3rd person singular present\n",
      "the                  DET                  DT                   Queen                determiner                               determiner\n",
      "Queen                PROPN                NNP                  consulted            proper noun                              noun, proper singular\n",
      "had                  AUX                  VBD                  consulted            auxiliary                                verb, past tense\n",
      "been                 AUX                  VBN                  consulted            auxiliary                                verb, past participle\n",
      "consulted            VERB                 VBN                  say                  verb                                     verb, past participle\n",
      "on                   ADP                  IN                   consulted            adposition                               conjunction, subordinating or preposition\n",
      "all                  DET                  PDT                  arrangements         determiner                               predeterminer\n",
      "the                  DET                  DT                   arrangements         determiner                               determiner\n",
      "arrangements         NOUN                 NNS                  on                   noun                                     noun, plural\n",
      ".                    PUNCT                .                    say                  punctuation                              punctuation mark, sentence closer\n",
      "\n",
      "                    SPACE                _SP                  .                    space                                    whitespace\n",
      "Among                ADP                  IN                   are                  adposition                               conjunction, subordinating or preposition\n",
      "those                PRON                 DT                   Among                pronoun                                  determiner\n",
      "to                   PART                 TO                   confirm              particle                                 infinitival \"to\"\n",
      "confirm              VERB                 VB                   those                verb                                     verb, base form\n",
      "their                PRON                 PRP$                 attendance           pronoun                                  pronoun, possessive\n",
      "attendance           NOUN                 NN                   confirm              noun                                     noun, singular or mass\n",
      "at                   ADP                  IN                   confirm              adposition                               conjunction, subordinating or preposition\n",
      "the                  DET                  DT                   funeral              determiner                               determiner\n",
      "state                NOUN                 NN                   funeral              noun                                     noun, singular or mass\n",
      "funeral              NOUN                 NN                   at                   noun                                     noun, singular or mass\n",
      ",                    PUNCT                ,                    funeral              punctuation                              punctuation mark, comma\n",
      "which                PRON                 WDT                  starts               pronoun                                  wh-determiner\n",
      "starts               VERB                 VBZ                  funeral              verb                                     verb, 3rd person singular present\n",
      "at                   ADP                  IN                   starts               adposition                               conjunction, subordinating or preposition\n",
      "11:00                NUM                  CD                   BST                  numeral                                  cardinal number\n",
      "BST                  PROPN                NNP                  at                   proper noun                              noun, proper singular\n",
      ",                    PUNCT                ,                    are                  punctuation                              punctuation mark, comma\n",
      "are                  AUX                  VBP                  are                  auxiliary                                verb, non-3rd person singular present\n",
      "US                   PROPN                NNP                  President            proper noun                              noun, proper singular\n",
      "President            PROPN                NNP                  Biden                proper noun                              noun, proper singular\n",
      "Joe                  PROPN                NNP                  Biden                proper noun                              noun, proper singular\n",
      "Biden                PROPN                NNP                  are                  proper noun                              noun, proper singular\n",
      "and                  CCONJ                CC                   Biden                coordinating conjunction                 conjunction, coordinating\n",
      "French               ADJ                  JJ                   President            adjective                                adjective (English), other noun-modifier (Chinese)\n",
      "President            PROPN                NNP                  Macron               proper noun                              noun, proper singular\n",
      "Emmanuel             PROPN                NNP                  Macron               proper noun                              noun, proper singular\n",
      "Macron               PROPN                NNP                  Biden                proper noun                              noun, proper singular\n",
      ".                    PUNCT                .                    are                  punctuation                              punctuation mark, sentence closer\n",
      "\n",
      "                    SPACE                _SP                  .                    space                                    whitespace\n",
      "Alongside            ADP                  IN                   be                   adposition                               conjunction, subordinating or preposition\n",
      "royalty              NOUN                 NN                   Alongside            noun                                     noun, singular or mass\n",
      ",                    PUNCT                ,                    be                   punctuation                              punctuation mark, comma\n",
      "politicians          NOUN                 NNS                  be                   noun                                     noun, plural\n",
      "and                  CCONJ                CC                   politicians          coordinating conjunction                 conjunction, coordinating\n",
      "world                NOUN                 NN                   leaders              noun                                     noun, singular or mass\n",
      "leaders              NOUN                 NNS                  politicians          noun                                     noun, plural\n",
      "will                 AUX                  MD                   be                   auxiliary                                verb, modal auxiliary\n",
      "be                   AUX                  VB                   be                   auxiliary                                verb, base form\n",
      "200                  NUM                  CD                   people               numeral                                  cardinal number\n",
      "people               NOUN                 NNS                  be                   noun                                     noun, plural\n",
      "who                  PRON                 WP                   recognised           pronoun                                  wh-pronoun, personal\n",
      "were                 AUX                  VBD                  recognised           auxiliary                                verb, past tense\n",
      "recognised           VERB                 VBN                  people               verb                                     verb, past participle\n",
      "in                   ADP                  IN                   recognised           adposition                               conjunction, subordinating or preposition\n",
      "the                  DET                  DT                   Queen                determiner                               determiner\n",
      "Queen                PROPN                NNP                  Honours              proper noun                              noun, proper singular\n",
      "'s                   PART                 POS                  Queen                particle                                 possessive ending\n",
      "Birthday             PROPN                NNP                  Honours              proper noun                              noun, proper singular\n",
      "Honours              PROPN                NNP                  in                   proper noun                              noun, proper singular\n",
      ",                    PUNCT                ,                    Honours              punctuation                              punctuation mark, comma\n",
      "including            VERB                 VBG                  Honours              verb                                     verb, gerund or present participle\n",
      "those                PRON                 DT                   including            pronoun                                  determiner\n",
      "who                  PRON                 WP                   helped               pronoun                                  wh-pronoun, personal\n",
      "helped               VERB                 VBD                  those                verb                                     verb, past tense\n",
      "with                 ADP                  IN                   helped               adposition                               conjunction, subordinating or preposition\n",
      "the                  DET                  DT                   response             determiner                               determiner\n",
      "response             NOUN                 NN                   with                 noun                                     noun, singular or mass\n",
      "to                   ADP                  IN                   response             adposition                               conjunction, subordinating or preposition\n",
      "the                  DET                  DT                   pandemic             determiner                               determiner\n",
      "coronavirus          NOUN                 NN                   pandemic             noun                                     noun, singular or mass\n",
      "pandemic             ADJ                  JJ                   to                   adjective                                adjective (English), other noun-modifier (Chinese)\n",
      ".                    PUNCT                .                    be                   punctuation                              punctuation mark, sentence closer\n",
      "\n",
      "                    SPACE                _SP                  .                    space                                    whitespace\n",
      "A                    DET                  DT                   officer              determiner                               determiner\n",
      "former               ADJ                  JJ                   officer              adjective                                adjective (English), other noun-modifier (Chinese)\n",
      "police               NOUN                 NN                   officer              noun                                     noun, singular or mass\n",
      "officer              NOUN                 NN                   awarded              noun                                     noun, singular or mass\n",
      "awarded              VERB                 VBD                  awarded              verb                                     verb, past tense\n",
      "the                  DET                  DT                   Cross                determiner                               determiner\n",
      "George               PROPN                NNP                  Cross                proper noun                              noun, proper singular\n",
      "Cross                PROPN                NNP                  awarded              proper noun                              noun, proper singular\n",
      "after                ADP                  IN                   awarded              adposition                               conjunction, subordinating or preposition\n",
      "being                AUX                  VBG                  shot                 auxiliary                                verb, gerund or present participle\n",
      "shot                 VERB                 VBN                  after                verb                                     verb, past participle\n",
      "15                   NUM                  CD                   times                numeral                                  cardinal number\n",
      "times                NOUN                 NNS                  shot                 noun                                     noun, plural\n",
      "is                   AUX                  VBZ                  awarded              auxiliary                                verb, 3rd person singular present\n",
      "among                ADP                  IN                   is                   adposition                               conjunction, subordinating or preposition\n",
      "those                PRON                 DT                   among                pronoun                                  determiner\n",
      "due                  ADJ                  JJ                   those                adjective                                adjective (English), other noun-modifier (Chinese)\n",
      "to                   PART                 TO                   attend               particle                                 infinitival \"to\"\n",
      "attend               VERB                 VB                   due                  verb                                     verb, base form\n",
      "the                  DET                  DT                   funeral              determiner                               determiner\n",
      "state                NOUN                 NN                   funeral              noun                                     noun, singular or mass\n",
      "funeral              NOUN                 NN                   attend               noun                                     noun, singular or mass\n",
      ".                    PUNCT                .                    awarded              punctuation                              punctuation mark, sentence closer\n",
      "\n",
      "                    SPACE                _SP                  .                    space                                    whitespace\n",
      "Tony                 PROPN                NNP                  Gledhill             proper noun                              noun, proper singular\n",
      "Gledhill             PROPN                NNP                  said                 proper noun                              noun, proper singular\n",
      ",                    PUNCT                ,                    Gledhill             punctuation                              punctuation mark, comma\n",
      "84                   NUM                  CD                   Gledhill             numeral                                  cardinal number\n",
      ",                    PUNCT                ,                    Gledhill             punctuation                              punctuation mark, comma\n",
      "said                 VERB                 VBD                  said                 verb                                     verb, past tense\n",
      ":                    PUNCT                :                    said                 punctuation                              punctuation mark, colon or ellipsis\n",
      "\"                    PUNCT                ``                   said                 punctuation                              opening quotation mark\n",
      "I                    PRON                 PRP                  'm                   pronoun                                  pronoun, personal\n",
      "'m                   AUX                  VBP                  said                 auxiliary                                verb, non-3rd person singular present\n",
      "incredibly           ADV                  RB                   moved                adverb                                   adverb\n",
      "moved                VERB                 VBN                  'm                   verb                                     verb, past participle\n",
      "to                   PART                 TO                   involved             particle                                 infinitival \"to\"\n",
      "be                   AUX                  VB                   involved             auxiliary                                verb, base form\n",
      "involved             VERB                 VBN                  moved                verb                                     verb, past participle\n",
      ".                    PUNCT                .                    said                 punctuation                              punctuation mark, sentence closer\n",
      "\"                    PUNCT                ``                   said                 punctuation                              opening quotation mark\n",
      "\n",
      "                    SPACE                _SP                  \"                    space                                    whitespace\n",
      "The                  DET                  DT                   organiser            determiner                               determiner\n",
      "official             ADJ                  JJ                   organiser            adjective                                adjective (English), other noun-modifier (Chinese)\n",
      "organiser            NOUN                 NN                   said                 noun                                     noun, singular or mass\n",
      "of                   ADP                  IN                   organiser            adposition                               conjunction, subordinating or preposition\n",
      "Monday               PROPN                NNP                  events               proper noun                              noun, proper singular\n",
      "'s                   PART                 POS                  Monday               particle                                 possessive ending\n",
      "events               NOUN                 NNS                  of                   noun                                     noun, plural\n",
      ",                    PUNCT                ,                    said                 punctuation                              punctuation mark, comma\n",
      "the                  DET                  DT                   Marshal              determiner                               determiner\n",
      "Earl                 PROPN                NNP                  Marshal              proper noun                              noun, proper singular\n",
      "Marshal              PROPN                NNP                  said                 proper noun                              noun, proper singular\n",
      ",                    PUNCT                ,                    Marshal              punctuation                              punctuation mark, comma\n",
      "the                  DET                  DT                   Duke                 determiner                               determiner\n",
      "Duke                 PROPN                NNP                  Marshal              proper noun                              noun, proper singular\n",
      "of                   ADP                  IN                   Duke                 adposition                               conjunction, subordinating or preposition\n",
      "Norfolk              PROPN                NNP                  of                   proper noun                              noun, proper singular\n",
      ",                    PUNCT                ,                    Marshal              punctuation                              punctuation mark, comma\n",
      "said                 VERB                 VBD                  said                 verb                                     verb, past tense\n",
      "his                  PRON                 PRP$                 role                 pronoun                                  pronoun, possessive\n",
      "role                 NOUN                 NN                   was                  noun                                     noun, singular or mass\n",
      "was                  AUX                  VBD                  humbling             auxiliary                                verb, past tense\n",
      "\"                    PUNCT                ``                   humbling             punctuation                              opening quotation mark\n",
      "both                 PRON                 DT                   humbling             pronoun                                  determiner\n",
      "humbling             VERB                 VBG                  said                 verb                                     verb, gerund or present participle\n",
      "and                  CCONJ                CC                   humbling             coordinating conjunction                 conjunction, coordinating\n",
      "daunting             VERB                 VBG                  humbling             verb                                     verb, gerund or present participle\n",
      "\"                    PUNCT                ''                   humbling             punctuation                              closing quotation mark\n",
      ".                    PUNCT                .                    said                 punctuation                              punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f\"{token.text :<20} {token.pos_:<20} {token.tag_:<20} {token.head.text:<20} {spacy.explain(token.pos_):<40} {spacy.explain(token.tag_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting category of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[additions, plans, day, touches, playing, lament, piper, state, funeral, events, minute, silence, service, close, midday, order, service, choice, music, readings, choices, funeral, aides, arrangements, attendance, state, funeral, royalty, politicians, world, leaders, people, response, coronavirus, police, officer, times, state, funeral, organiser, events, role] [personal, funeral, likely, biggest, single, ceremonial, national, more, personal, French, pandemic, former, due, official]\n"
     ]
    }
   ],
   "source": [
    "nouns = []\n",
    "adjectives = []\n",
    "for token in doc:\n",
    "    if token.pos_ == 'NOUN':\n",
    "        nouns.append(token)\n",
    "    if token.pos_ == 'ADJ':\n",
    "        adjectives.append(token)\n",
    "\n",
    "print(nouns, adjectives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"9839390c0b454cb58fadacd084b782ed-0\" class=\"displacy\" width=\"1450\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">He</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">interested</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">learn</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Natural</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Language</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">Processing</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9839390c0b454cb58fadacd084b782ed-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9839390c0b454cb58fadacd084b782ed-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9839390c0b454cb58fadacd084b782ed-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9839390c0b454cb58fadacd084b782ed-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9839390c0b454cb58fadacd084b782ed-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9839390c0b454cb58fadacd084b782ed-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9839390c0b454cb58fadacd084b782ed-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9839390c0b454cb58fadacd084b782ed-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9839390c0b454cb58fadacd084b782ed-0-4\" stroke-width=\"2px\" d=\"M945,177.0 C945,89.5 1095.0,89.5 1095.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9839390c0b454cb58fadacd084b782ed-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,179.0 L937,167.0 953,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9839390c0b454cb58fadacd084b782ed-0-5\" stroke-width=\"2px\" d=\"M1120,177.0 C1120,89.5 1270.0,89.5 1270.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9839390c0b454cb58fadacd084b782ed-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,179.0 L1112,167.0 1128,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9839390c0b454cb58fadacd084b782ed-0-6\" stroke-width=\"2px\" d=\"M770,177.0 C770,2.0 1275.0,2.0 1275.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9839390c0b454cb58fadacd084b782ed-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,179.0 L1283.0,167.0 1267.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "simple_text = \"He is interested to learn Natural Language Processing\"\n",
    "simple_doc = nlp(simple_text)\n",
    "# displacy.serve(simple_doc, style=\"dep\")\n",
    "displacy.render(simple_doc, style=\"dep\", jupyter = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsubj  :  nominal subject\n",
      "acomp  :  adjectival complement\n",
      "xcomp  :  open clausal complement\n",
      "aux  :  auxiliary\n",
      "dobj  :  direct object\n"
     ]
    }
   ],
   "source": [
    "dep_tags = [\"nsubj\",\"acomp\", \"xcomp\", \"aux\", \"dobj\"]\n",
    "\n",
    "for tag in dep_tags:\n",
    "    print(tag, \" : \", spacy.explain(tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(123) 456 789'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ORTH : Exact text of the token \n",
    "SHAPE : Transforms the token string to orthographic features\n",
    "OP : operators. Using ? indicates that the pattern is optional.\n",
    "'''\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "roger_fed_text = \"Roger Federer whose phoe number is (123) 456 789 retired from professional tennis yesterday.\"\n",
    "\n",
    "def extract_phone_number(nlp_doc): \n",
    "    pattern = [\n",
    "        {'ORTH': '('}, {'SHAPE': 'ddd'},\n",
    "        {'ORTH': ')'}, {'SHAPE': 'ddd'},\n",
    "        {'ORTH': '-', 'OP': '?'},\n",
    "        {'SHAPE': 'ddd'}\n",
    "    ]\n",
    "    matcher.add('PHONE_NUMBER', [pattern], on_match=None)\n",
    "    matches = matcher(nlp_doc)\n",
    "    for match_id, start, end in matches:\n",
    "        span = nlp_doc[start:end]\n",
    "        return span.text \n",
    "\n",
    "rf_doc = nlp(roger_fed_text)\n",
    "extract_phone_number(rf_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shallow Processing / Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual Conference\n",
      "Invent\n",
      "Las Vegas\n",
      "mid November\n"
     ]
    }
   ],
   "source": [
    "text = \"AWS Annual Conference Re:Invent happens every year in Las Vegas around mid November.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This park\n",
      "everything\n",
      "you\n",
      "a big hill\n",
      "kids\n",
      "-leash\n",
      "which\n",
      "adorable puppies\n",
      "tennis courts\n",
      "green lawns\n",
      "great views\n",
      "the CN Tower\n",
      "I\n",
      "my son\n",
      "the playground\n",
      "the west end\n",
      "the grass\n",
      "It\n",
      "all aspects\n",
      "society\n",
      "frat boys\n",
      "ball games\n",
      "one side\n",
      "families\n",
      "another\n",
      "hippies\n",
      "drum circles\n",
      "the south end\n",
      "Queen st\n",
      "It\n",
      "a fantastic place\n",
      "Torontos cultural diversity\n"
     ]
    }
   ],
   "source": [
    "text = '''This park has everything you could ask for: a big hill for kids to roll down, an off-leash dog area (which is always full of adorable puppies), tennis courts, and sprawling green lawns with great views of the CN Tower. I take my son to the playground near the west end and sunbathe on the grass nearby. Its big enough that all aspects of society are accommodated comfortably; frat boys playing ball games on one side, families on another, hippies and drum circles tend to gather near the south end by Queen st. Its a fantastic place to appreciate Torontos cultural diversity.'''\n",
    "doc = nlp(text)\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verb Phrase Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textacy in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (0.12.0)\n",
      "Requirement already satisfied: jellyfish>=0.8.0 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from textacy) (0.9.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from textacy) (2.8.6)\n",
      "Requirement already satisfied: pyphen>=0.10.0 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from textacy) (0.13.0)\n",
      "Requirement already satisfied: tqdm>=4.19.6 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from textacy) (4.64.1)\n",
      "Requirement already satisfied: joblib>=0.13.0 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from textacy) (1.2.0)\n",
      "Requirement already satisfied: cytoolz>=0.10.1 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from textacy) (0.12.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from textacy) (1.9.1)\n",
      "Requirement already satisfied: catalogue~=2.0 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from textacy) (2.0.8)\n",
      "Requirement already satisfied: requests>=2.10.0 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from textacy) (2.28.1)\n",
      "Requirement already satisfied: spacy>=3.0.0 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from textacy) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from textacy) (1.23.3)\n",
      "Requirement already satisfied: cachetools>=4.0.0 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from textacy) (5.2.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.0 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from textacy) (1.1.2)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from cytoolz>=0.10.1->textacy) (0.12.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from requests>=2.10.0->textacy) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from requests>=2.10.0->textacy) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from requests>=2.10.0->textacy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from requests>=2.10.0->textacy) (1.26.12)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from scikit-learn>=0.19.0->textacy) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from spacy>=3.0.0->textacy) (58.0.4)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from spacy>=3.0.0->textacy) (1.0.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from spacy>=3.0.0->textacy) (2.4.4)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from spacy>=3.0.0->textacy) (0.4.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from spacy>=3.0.0->textacy) (0.6.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from spacy>=3.0.0->textacy) (8.1.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from spacy>=3.0.0->textacy) (3.3.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from spacy>=3.0.0->textacy) (0.10.1)\n",
      "Requirement already satisfied: jinja2 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from spacy>=3.0.0->textacy) (3.1.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from spacy>=3.0.0->textacy) (1.9.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from spacy>=3.0.0->textacy) (3.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from spacy>=3.0.0->textacy) (3.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from spacy>=3.0.0->textacy) (21.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from spacy>=3.0.0->textacy) (1.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from spacy>=3.0.0->textacy) (2.0.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from packaging>=20.0->spacy>=3.0.0->textacy) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from pathy>=0.3.5->spacy>=3.0.0->textacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy>=3.0.0->textacy) (4.3.0)\n",
      "Requirement already satisfied: blis<0.10.0,>=0.7.8 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.0.0->textacy) (0.9.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.0.0->textacy) (0.0.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy>=3.0.0->textacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sauravbhattacharyya/Desktop/DataScience2022/venv/lib/python3.9/site-packages (from jinja2->spacy>=3.0.0->textacy) (2.1.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/Users/sauravbhattacharyya/Desktop/DataScience2022/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy\n",
    "text = '''This park has everything you could ask for: a big hill for kids to roll down, an off-leash dog area (which is always full of adorable puppies), tennis courts, and sprawling green lawns with great views of the CN Tower. I take my son to the playground near the west end and sunbathe on the grass nearby. Its big enough that all aspects of society are accommodated comfortably; frat boys playing ball games on one side, families on another, hippies and drum circles tend to gather near the south end by Queen st. Its a fantastic place to appreciate Torontos cultural diversity.'''\n",
    "\n",
    "\n",
    "pattern = r'(<VERB>+)'\n",
    "doc = textacy.make_spacy_doc(text, \"en_core_web_sm\")\n",
    "\n",
    "# TBD...\n",
    "# for chunk in textacy.extract.regex_matches(doc, pattern):\n",
    "#     print(chunk.text)\n",
    "\n",
    "# for chunk in doc.noun_chunks:\n",
    "#     print(chunk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roger Federer                  0 13 PERSON                         People, including fictional\n",
      "James Brooks                   15 27 PERSON                         People, including fictional\n",
      "Rafael Nadal                   29 41 PERSON                         People, including fictional\n",
      "Venus Williams                 46 60 PERSON                         People, including fictional\n",
      "the early 21st century         111 133 DATE                           Absolute or relative dates or periods\n",
      "Maria Sharapova                135 150 PERSON                         People, including fictional\n"
     ]
    }
   ],
   "source": [
    "text = '''Roger Federer, James Brooks, Rafael Nadal and Venus Williams will be reckoned as the torch bearer of tennis in the early 21st century. Maria Sharapova belongs to the earlier generation.'''\n",
    "\n",
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text:<30} {ent.start_char} {ent.end_char} {ent.label_:<30} {spacy.explain(ent.label_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Roger Federer\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    James Brooks\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Rafael Nadal\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Venus Williams\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " will be reckoned as the torch bearer of tennis in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the early 21st century\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Maria Sharapova\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " belongs to the earlier generation.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REDACTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[REDACTED] , [REDACTED] , [REDACTED] and [REDACTED] will be reckoned as the torch bearer of tennis in the early 21st century . [REDACTED] belongs to the earlier generation .'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import replace\n",
    "\n",
    "\n",
    "text = '''Roger Federer, James Brooks, Rafael Nadal and Venus Williams will be reckoned as the torch bearer of tennis in the early 21st century. Maria Sharapova belongs to the earlier generation.'''\n",
    "\n",
    "def replace_person_names(token):\n",
    "    if token.ent_iob != 0 and token.ent_type_ == 'PERSON':\n",
    "        return '[REDACTED]'\n",
    "    return token.text \n",
    "\n",
    "def redact_names(nlp_doc):\n",
    "    doc = nlp_doc \n",
    "    with doc.retokenize() as retokenizer:\n",
    "        for ent in doc.ents:\n",
    "            retokenizer.merge(ent)\n",
    "    tokens = map(replace_person_names, nlp_doc)\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "doc = nlp(text)\n",
    "redact_names(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEMANTIC SIMILARITY & WORD VECTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8325487248355983"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "doc1 = nlp(\"What a bright morning\")\n",
    "doc2 = nlp(\"What a bright morning to start with\")\n",
    "\n",
    "doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.language import Language\n",
    "\n",
    "@Language.component(\"my_custom_component\")\n",
    "def custom_component(doc):\n",
    "    print(f\"Ther are {len(doc)} tokens in the text.\")\n",
    "    return doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner',\n",
       " 'my_custom_component']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(\"my_custom_component\")\n",
    "\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ther are 12 tokens in the text.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Where the mind is without fear and the head is held high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.titled_person(doc)>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.language import Language\n",
    "from spacy.tokens import Span\n",
    "from spacy.util import filter_spans\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "@Language.component(\"titled_person\")\n",
    "def titled_person(doc):\n",
    "    pattern = [ \n",
    "        {\"IS_ALPHA\" : True, \"IS_TITLE\": True},\n",
    "        {\"IS_STOP\": True},\n",
    "        {\"IS_ALPHA\" : True, \"IS_TITLE\": True}\n",
    "    ]\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    matcher.add(\"TITLED PERSON\", [pattern])\n",
    "\n",
    "    matches = matcher(doc)\n",
    "    matched_spans = [Span(doc, start, end, label=\"PERSON\") for _, start, end in matches]\n",
    "\n",
    "    filtered_matches = filter_spans(list(doc.ents) + matched_spans)\n",
    "    doc.ents = filtered_matches\n",
    "\n",
    "    return doc \n",
    "\n",
    "nlp.add_pipe(\"titled_person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Roger Federer, James Brooks, Rafael Nadal & Venus Williams will be reckoned as the torch bearer of tennis in the early 21st century. Maria Sharapova belongs to the earlier generation.'''\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Roger Federer,\n",
       " James Brooks,\n",
       " Rafael Nadal & Venus Williams,\n",
       " the early 21st century,\n",
       " Maria Sharapova)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner',\n",
       " 'titled_person']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59c0d54295269212dacd944a2be0139f5619541711cd1c2d99809e4682da3f84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
