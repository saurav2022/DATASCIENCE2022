{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sauravbhattacharyya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package state_union to\n",
      "[nltk_data]     /Users/sauravbhattacharyya/nltk_data...\n",
      "[nltk_data]   Package state_union is already up-to-date!\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/sauravbhattacharyya/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sauravbhattacharyya/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/sauravbhattacharyya/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download([\"stopwords\", \"state_union\", \"twitter_samples\", \"wordnet\", \"omw-1.4\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.corpus.stopwords.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_words = [word for word in nltk.corpus.state_union.words() if word.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350715"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(union_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_words[20000:20051]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Donald Trump should be feeling very nervous about the investigation into the classified documents he kept at his estate in Florida, says a former federal prosecutor. \n",
    "\n",
    "The U.S. Justice Department on Friday released a heavily redacted copy of the FBI affidavit used to obtain a search warrant for the former president's Mar-a-Lago estate earlier this month. \n",
    "\n",
    "In the affidavit, prosecutors wrote that there was \"probable cause to believe that evidence of obstruction will be found.\n",
    "\n",
    "The warrant was issued after investigators pored through 15 boxes of White House documents from Mar-a-Lago that Trump turned over to the National Archives and Records Administration earlier this year. According to the affidavit, 14 of those boxes contained classified documents, many of them top secret.\n",
    "\n",
    "Trump says he's co-operated fully with investigators, and painted the search as a politically motivated witch hunt intended to damage his re-election prospects. \n",
    "\n",
    "Gene Rossi, a former U.S. federal prosecutor and former Democratic candidate for lieutenant governor of Virginia, spoke to As It Happens guest host Susan Bonner about the affidavit. Here is part of their conversation.\n",
    "\n",
    "Mr. Rossi, what do these documents tell you about the investigation that is underway around the former president, Donald Trump?\n",
    "\n",
    "It tells me, as a former federal prosecutor, that this investigation has gone to a very high level. To get a search warrant against the [former] president of the United States' home is a monumental ask on the part of the Justice Department. And they went through an incredibly meticulous process to develop probable cause for the following:\n",
    "\n",
    "When president Trump left office, left the White House, he committed at least two crimes, arguably, by the Department of Justice affidavit. One, he violated the [Presidential] Records Act. No. 2, he violated the Espionage Act when he left.\n",
    "\n",
    "Because why? He wilfully and knowingly, allegedly, took documents that were top secret SCI [sensitive compartmented information]. That is the gold standard of classified documents. They should never leave a secure facility. He brought them to his summer home, if you will, and kept them in an unsecured location. That is a violation of the law. Period. End of story. So this is a very serious investigation.\"\"\"\n",
    "\n",
    "news_corpus = nltk.word_tokenize(text)\n",
    "print(news_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 19191, 'of': 12854, 'to': 11868, 'and': 11748, 'in': 6936, 'a': 5837, 'our': 5141, 'we': 4338, 'that': 4309, 'for': 4070, ...})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = nltk.FreqDist(union_words)\n",
    "fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most commonly used words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 19191), ('of', 12854), ('to', 11868)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  the    of    to   and    in     a   our    we  that   for    is     I  will  have    be  this   are    We    on  with    it    by    as   all   not  must   The     s   can  more \n",
      "19191 12854 11868 11748  6936  5837  5141  4338  4309  4070  3621  3394  2959  2486  2481  2323  2273  2063  1857  1825  1767  1717  1663  1612  1591  1568  1520  1410  1396  1369 \n"
     ]
    }
   ],
   "source": [
    "fd.tabulate(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "stopwords.append(\"us\")\n",
    "union_words_net = [word for word in union_words if word.lower() not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179540"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(union_words_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_words_net[2000:2051]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['should', 'be', 'very', 'about', 'the', 'into', 'the', 'he', 'at', 'his', 'in', 'a', 'The', 'on', 'a', 'of', 'the', 'to', 'a', 'for', 'the', 'this', 'In', 'the', 'that', 'there', 'was', 'to', 'that', 'of', 'will', 'be', 'The', 'was', 'after', 'through', 'of', 'from', 'that', 'over', 'to', 'the', 'and', 'this', 'to', 'the', 'of', 'those', 'of', 'them', 'he', 'with', 'and', 'the', 'as', 'a', 'to', 'his', 'a', 'and', 'for', 'of', 'to', 'As', 'It', 'about', 'the', 'Here', 'is', 'of', 'their', 'what', 'do', 'these', 'you', 'about', 'the', 'that', 'is', 'the', 'It', 'me', 'as', 'a', 'that', 'this', 'has', 'to', 'a', 'very', 'To', 'a', 'against', 'the', 'of', 'the', 'is', 'a', 'on', 'the', 'of', 'the', 'And', 'they', 'through', 'an', 'to', 'for', 'the', 'When', 'the', 'he', 'at', 'by', 'the', 'of', 'he', 'the', 'No', 'he', 'the', 'when', 'he', 'Because', 'why', 'He', 'and', 'that', 'were', 'That', 'is', 'the', 'of', 'They', 'should', 'a', 'He', 'them', 'to', 'his', 'if', 'you', 'will', 'and', 'them', 'in', 'an', 'That', 'is', 'a', 'of', 'the', 'of', 'So', 'this', 'is', 'a', 'very']\n",
      "['Donald', 'Trump', 'feeling', 'nervous', 'investigation', 'classified', 'documents', 'kept', 'estate', 'Florida', ',', 'says', 'former', 'federal', 'prosecutor', '.', 'U.S.', 'Justice', 'Department', 'Friday', 'released', 'heavily', 'redacted', 'copy', 'FBI', 'affidavit', 'used', 'obtain', 'search', 'warrant', 'former', 'president', \"'s\", 'Mar-a-Lago', 'estate', 'earlier', 'month', '.', 'affidavit', ',', 'prosecutors', 'wrote', '``', 'probable', 'cause', 'believe', 'evidence', 'obstruction', 'found', '.', 'warrant', 'issued', 'investigators', 'pored', '15', 'boxes', 'White', 'House', 'documents', 'Mar-a-Lago', 'Trump', 'turned', 'National', 'Archives', 'Records', 'Administration', 'earlier', 'year', '.', 'According', 'affidavit', ',', '14', 'boxes', 'contained', 'classified', 'documents', ',', 'many', 'top', 'secret', '.', 'Trump', 'says', \"'s\", 'co-operated', 'fully', 'investigators', ',', 'painted', 'search', 'politically', 'motivated', 'witch', 'hunt', 'intended', 'damage', 're-election', 'prospects', '.', 'Gene', 'Rossi', ',', 'former', 'U.S.', 'federal', 'prosecutor', 'former', 'Democratic', 'candidate', 'lieutenant', 'governor', 'Virginia', ',', 'spoke', 'Happens', 'guest', 'host', 'Susan', 'Bonner', 'affidavit', '.', 'part', 'conversation', '.', 'Mr.', 'Rossi', ',', 'documents', 'tell', 'investigation', 'underway', 'around', 'former', 'president', ',', 'Donald', 'Trump', '?', 'tells', ',', 'former', 'federal', 'prosecutor', ',', 'investigation', 'gone', 'high', 'level', '.', 'get', 'search', 'warrant', '[', 'former', ']', 'president', 'United', 'States', \"'\", 'home', 'monumental', 'ask', 'part', 'Justice', 'Department', '.', 'went', 'incredibly', 'meticulous', 'process', 'develop', 'probable', 'cause', 'following', ':', 'president', 'Trump', 'left', 'office', ',', 'left', 'White', 'House', ',', 'committed', 'least', 'two', 'crimes', ',', 'arguably', ',', 'Department', 'Justice', 'affidavit', '.', 'One', ',', 'violated', '[', 'Presidential', ']', 'Records', 'Act', '.', '.', '2', ',', 'violated', 'Espionage', 'Act', 'left', '.', '?', 'wilfully', 'knowingly', ',', 'allegedly', ',', 'took', 'documents', 'top', 'secret', 'SCI', '[', 'sensitive', 'compartmented', 'information', ']', '.', 'gold', 'standard', 'classified', 'documents', '.', 'never', 'leave', 'secure', 'facility', '.', 'brought', 'summer', 'home', ',', ',', 'kept', 'unsecured', 'location', '.', 'violation', 'law', '.', 'Period', '.', 'End', 'story', '.', 'serious', 'investigation', '.']\n"
     ]
    }
   ],
   "source": [
    "news_stopwords = [w for w in news_corpus if w.lower() in stopwords]\n",
    "news_corpus_net =  [w for w in news_corpus if w.lower() not in stopwords]\n",
    "print(news_stopwords)\n",
    "print(news_corpus_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concordance & Collocation\n",
    "\n",
    "`Concordance` : Collection of word locations along with their context.\n",
    "Can be used to find:\n",
    "1. How many times the word appears\n",
    "2. Where each occurrence appears\n",
    "3. What words surround each occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 10 of 786 matches:\n",
      "uggle to preserve and maintain our American way of life . At this moment , Ame\n",
      "st do his duty . I appeal to every American , regardless of party , race , cre\n",
      "roach has become imperative if the American political and economic system is t\n",
      "- is to improve the welfare of the American people . In addition to economic p\n",
      "Last February and March an Inter - American Conference on Problems of War and \n",
      "y against any one of the sovereign American republics would be considered an a\n",
      "tack were made or threatened , the American republics would decide jointly , t\n",
      "all live than in the hearts of the American people . It is the hope of all Ame\n",
      "d , there are the vast majority of American businessmen who are not holding ba\n",
      "the goods and services produced by American industry and agriculture . At the \n"
     ]
    }
   ],
   "source": [
    "union_corpus = nltk.Text(nltk.corpus.state_union.words())\n",
    "union_corpus.concordance(\"american\", lines=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " would want us to do . That is what America will do . So much blood has already\n",
      "ay , the entire world is looking to America for enlightened leadership to peace\n",
      "beyond any shadow of a doubt , that America will continue the fight for freedom\n"
     ]
    }
   ],
   "source": [
    "union_corpus_cc_list = union_corpus.concordance_list(\"america\", lines=3)\n",
    "for entry in union_corpus_cc_list:\n",
    "    print(entry.line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocation\n",
    "\n",
    "Seris of words that frequently appear together in a given text.\n",
    "\n",
    "It is made of two or more words. NLTK provides classes to handle following types of collocations:\n",
    "1. Bigram : Frquent two-word combinations\n",
    "2. Trigram : ..3-word..\n",
    "3. Quadgram : ..4-word.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('the', 'United', 'States'), 294),\n",
       " (('the', 'American', 'people'), 185),\n",
       " (('of', 'the', 'world'), 154),\n",
       " (('of', 'the', 'United'), 145),\n",
       " (('to', 'the', 'Congress'), 139),\n",
       " (('in', 'the', 'world'), 131),\n",
       " (('the', 'fiscal', 'year'), 109),\n",
       " (('of', 'the', 'Congress'), 102),\n",
       " (('of', 'the', 'Union'), 102),\n",
       " (('the', 'Federal', 'Government'), 102)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union_corpus = [word for word in nltk.corpus.state_union.words() if word.isalpha()]\n",
    "union_corpus_trigram_cl = nltk.collocations.TrigramCollocationFinder.from_words(union_corpus)\n",
    "union_corpus_trigram_cl.ngram_fd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('of', 'the', 'United', 'States'), 110),\n",
       " (('I', 'ask', 'you', 'to'), 69),\n",
       " (('State', 'of', 'the', 'Union'), 58),\n",
       " (('STATE', 'OF', 'THE', 'UNION'), 52),\n",
       " (('ON', 'THE', 'STATE', 'OF'), 50),\n",
       " (('THE', 'STATE', 'OF', 'THE'), 50),\n",
       " (('in', 'the', 'fiscal', 'year'), 47),\n",
       " (('CONGRESS', 'ON', 'THE', 'STATE'), 46),\n",
       " (('the', 'state', 'of', 'the'), 45),\n",
       " (('of', 'the', 'American', 'people'), 42)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union_corpus_quadgram_cl = nltk.collocations.QuadgramCollocationFinder.from_words(union_corpus)\n",
    "union_corpus_quadgram_cl.ngram_fd.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "\n",
    "Break down the word into a simpler form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'build'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "pst = PorterStemmer()\n",
    "pst.stem(\"building\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'builder'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem(\"builder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'built'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem(\"built\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'build'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem(\"builds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build\n",
      "build\n",
      "built\n",
      "build\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "lst = LancasterStemmer()\n",
    "stm = [\"building\", \"builder\", \"built\", \"builds\"]\n",
    "for word in stm:\n",
    "    print(lst.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "\n",
    "Breaks down words from plural to singular form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rock'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Information -> Information\n",
    "# Horse -> Horses\n",
    "# Tiger -> Tigers \n",
    "# Corpus-> Corpora \n",
    "# Mitocondrion -> Mitocondria\n",
    "# Child -> Children\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer.lemmatize(\"rocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corpus'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"corpora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'child'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"children\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59c0d54295269212dacd944a2be0139f5619541711cd1c2d99809e4682da3f84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
